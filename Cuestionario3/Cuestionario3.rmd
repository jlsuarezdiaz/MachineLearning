---
title: 'Aprendizaje Automático - Cuestionario 3'
author: "Juan Luis Su?rez D?az"
date: "`r format(Sys.time(), '%d de %B de %Y')`"
output:
  pdf_document:
    fig_caption: yes
    highlight: haddock
    toc: no
    toc_depth: 2
    includes:
      in_header: mystyles.sty
bibliography: references.bib
fontsize: 10pt
geometry: a4paper, top=2.5cm, bottom=2.5cm, left=3cm, right=3cm
lang: es-ES
linestretch: 1
csl: ieee.csl
---
<!--
Highlights: default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, null
-->
<!--
include-after: |2-
  * * *
  Esta obra se distribuye bajo una [Licencia Creative Commons Atribución-NoComercial-CompartirIgual 4.0 Internacional](http://creativecommons.org/licenses/by-nc-sa/4.0/).
  
mainfont: Arial
monofont: Source Code Pro

abstract: La navegación segura en Internet se extiende lentamente debido a numerosas
  dificultades en los procesos necesarios para su implementación. En este texto se
  explican y se analizan tres propuestas dirigidas a la difusión de las comunicaciones
  seguras y a la mejora de la certificación y la autenticación. Se observan las nuevas
  funcionalidades que traerá el próximo estándar HTTP/2 y se realiza un ejemplo de
  instalación en un servidor. De la misma forma, se presenta una autoridad de certificación
  automatizada, Let's Encrypt, y se demuestra su funcionamiento mediante las implementaciones
  de cliente y servidor del protocolo asociado ACME. Por último, se explica el mecanismo
  de verificación de identidad mediante certificados Convergence, frente a las autoridades
  de certificación, y se muestra un ejemplo de su uso.
  
(Cosas que puedo añadir a la cabecera)
-->

<!--

Añadir imagenes:

\begin{figure}[h]
\centering
\includegraphics[width=10 cm]{./images/1_1.png}
\caption{Instalación de phoronix suite.\label{fig:phinst}}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=10 cm]{./images/1_2.png}
\caption{Lista de test disponibles.\label{fig:phtests}}
\end{figure}

-->

# Cuesti?n 1



## Soluci?n


# Cuesti?n 2



## Soluci?n


# Cuesti?n 3



## Solución


# Cuestión 4

*Considerar un modelo SVM y los siguientes datos de entrenamiento: Clase-1: $\{(1,1),(2,2),(2,0)\}$, Clase-2: $\{(0,0),(1,0),(0,1)\}$*

a) *Dibujar los puntos y construir por inspección el vector de pesos para el hiperplano óptimo y el margen óptimo.*

b) *¿Cuáles son los vectores soporte?*

c) *Construir la solución en el espacio dual. Comparar la solución con la del apartado (a)*

## Solución

Asignamos la etiqueta 1 a los datos de la clase 1 y la etiqueta -1 a los datos de la clase 2. Los puntos se distribuyen de la siguiente forma:

```{r, echo=F,warning=F}
data <- matrix(nrow = 6, ncol = 2)
data[1,] <- c(1,1)
data[2,] <- c(2,2)
data[3,] <- c(2,0)
data[4,] <- c(0,0)
data[5,] <- c(1,0)
data[6,] <- c(0,1)

label <- c(1,1,1,-1,-1,-1)

plot(data,col = label + 3, pch = label + 17)

```

Buscamos el hiperplano óptimo que separa los datos, y para ello buscamos un vector de pesos $(b w_1 w_2)$, con $w = (w_1 w_2)$ que minimice la función $\frac{1}{2}w^Tw = \frac{1}{2}(w_1^2+w_2^2)$ sujeta a las restricciones $y_n(w^Tx_n + b) \ge 1$, donde cada $x_n$ representa a un dato y cada $y_n$ su etiqueta asociada.

Las restricciones que obtenemos para los puntos dados son las siguientes:

\begin{eqnarray}
  (1,1) & \to & w_1+w_2+b \ge 1 \\
  (2,2) & \to & 2w_1 + 2w_2 + b \ge 1 \\
  (2,0) & \to & 2w_1 + b \ge 1 \\
  (0,0) & \to & -b \ge 1 \\
  (1,0) & \to & -w_1 - b \ge 1 \\
  (0,1) & \to & -w_2 - b \ge 1 
\end{eqnarray}

Sumando las inecuaciones (1) y (5), obtenemos que $w_2 \ge 2$, y sumando las inecuaciones (1) y (6) $w_1 \ge 2$. Además se verifica que $\frac{1}{2}w^Tw$ sujeta a que $w_1,w_2 \ge 2$ alcanza su mínimo cuando $w_1=w_2=2$. Tomando estos valores para $w$ las desigualdades anteriores quedan:

\begin{eqnarray}
  (1,1) & \to & 4+b \ge 1 \\
  (2,2) & \to & 8 + b \ge 1 \\
  (2,0) & \to & 4 + b \ge 1 \\
  (0,0) & \to & b \le -1 \\
  (1,0) & \to & b \le -3 \\
  (0,1) & \to & b \le -3 
\end{eqnarray}

Por tanto, observamos que tomando $b = -3$ se satisfacen todas las restricciones, y además se minimiza $\frac{1}{2}w^Tw$ sobre estas restricciones. Por tanto, el vector de pesos asociados al hiperplano es $(b w_1 w_2)=(-3 2 2)$ y por tanto el hiperplano óptimo que separa los datos viene dado por la ecuación $2u + 2v = 3$. En la siguiente gráfica se muestra la recta obtenida:

```{r, echo=F,warning=F}
coefs_recta_explicita <- function(coefs_recta_impl){
  return(c(-coefs_recta_impl[1]/coefs_recta_impl[2],-coefs_recta_impl[3]/coefs_recta_impl[2]))
}

plot(data,col = label + 3, pch = label + 17)

r <- coefs_recta_explicita(c(2,2,-3))
abline(r[2],r[1],col = "green")

```

Finalmente, el margen óptimo viene dado por la fórmula $M = \frac{1}{\|w\|} = \frac{1}{\sqrt{w_1^2+w_2^2}}=\frac{1}{\sqrt{8}}$

b)

Los vectores soporte son aquellos para los que la distancia al hiperplano coincide con el margen, o equivalentemente, aquellos para los que se da la igualdad en la restricción asociada. Para ello,  para cada dato y con el vector de pesos obtenido $(b w_1 w_2)=(-3 2 2)$, calculamos $y_n(w^Tx_n + b)$ y vemos si es igual a 1.
 

\begin{eqnarray}
  (1,1) & \to & w_1+w_2+b = 1 \\
  (2,2) & \to & 2w_1 + 2w_2 + b = 5 \\
  (2,0) & \to & 2w_1 + b = 1 \\
  (0,0) & \to & -b = 3 \\
  (1,0) & \to & -w_1 - b = 1 \\
  (0,1) & \to & -w_2 - b = 1 
\end{eqnarray}

Por tanto, obtenemos que los vectores soporte son $(1,1),(2,0),(1,0)$ y $(0,1)$. En la gráfica anterior se comprueba que son los más cercanos al hiperplano.



# Cuesti?n 5



## Soluci?n





# Cuesti?n 6



## Soluci?n




# Cuesti?n 7



## Soluci?n



