---
title: "Trabajo 3"
author: "Nuria Rodríguez Barroso"
date: "`r format(Sys.time(), '%d de %B de %Y')`"
output: pdf_document
---

```{r echo = FALSE}
    #Fijamos la semilla para obtener siempre los mismos resultados
    set.seed(123456789)
```

#Clasificación.

```{r echo = FALSE, warning=FALSE}
  
    #PREPARACIÓN DE LOS DATOS
    sahd <- read.table("./data/SAHD", sep=",",head=T, row.names = 1)
    summary(sahd)
    
    

    #PREPROCESAMIENTO DE LOS DATOS

    #Paso 1: Modificamos las variables cualitativas (el programa no sabe bien cómo tratarlas)
    #La única variable cualitativa es famhist = {present, absent}
    sahd[,5] <- ifelse(sahd[,5]=='Present',1,0)
    #sahd[,11] <- ifelse(sahd[,5]==1, 0,1) # Tal vez esta sea redundante, porque famhist solo toma dos valores
    colnames(sahd) <- c('sbp', 'tobacco', 'ldl', 'adiposity', 'present_famhist', 'typea', 'obesity', 'alcohol', 'age', 'chd')#, 'absent_famhist')
    #sahd <- sahd[c('sbp', 'tobacco', 'ldl', 'adiposity', 'present_famhist', 'absent_famhist', 'typea', 'obesity', 'alcohol', 'age', 'chd')]
    
    attach(sahd)
    pairs(~ sbp + tobacco + ldl + adiposity + present_famhist +typea + obesity + alcohol + age, data= sahd, col = chd+3)
```

```{r echo = FALSE, warning=FALSE}
    
    #Paso 2: No hay columnas que contengan status ni redundantes

    #Paso 3: Eliminación de variables con varianza 0 o muy próximas (importante para métodos sensibles a distancias)
    library("e1071")
    
    #skewness -> medida de la asimetría de los datos
    skewness(sbp)
    skewness(tobacco)
    skewness(ldl)
    skewness(adiposity)
    skewness(typea)
    skewness(obesity)
    skewness(alcohol)
    skewness(age)
    skewness(present_famhist)
    #skewness(absent_famhist)
    
    #Los datos más asimétricos son -> tobacco y alcohol
    hist(tobacco)
    hist(alcohol)
    
```


```{r, echo=F,warning=F}
    
    #Ordenamos las columnas por asimetria
    sahd_asymmetry <- apply(sahd, 2, skewness)
    sort(abs(sahd_asymmetry), decreasing = T)
    
    #Una vez hemos hallado los datos con asimetría alta, aplicamos la transformación, para ello
    library("caret")
    
    #Lo aplico a los que tienen skewness > 1 ?????
    #BoxCoxTrans no hace la transformación, devuelve el parámetro
    BoxCoxTrans(alcohol) #No se aplica transformación pues no se ha encontrado el parámetro
    BoxCoxTrans(tobacco) #No se aplica transformación pues no se ha encontrado el parámetro
    ldl_trans <- BoxCoxTrans(ldl) #Se aplica transformación con lambda = 0
    sbp_trans <- BoxCoxTrans(sbp) #Lambda estimado -1.8
    
    #Transformamos los datos para los que no se ha encontrado lambda añadiendo una constante
    correction <- 1
    c_alcohol <- alcohol + min(alcohol)+correction
    c_tobacco <- tobacco + min(tobacco)+correction
    alcohol_trans <- BoxCoxTrans(c_alcohol)
    tobacco_trans <- BoxCoxTrans(c_tobacco)
    
    #Aplicamos la transformación a los que han devuelto un lambda
    #predict(ldl_trans, ldl) #Aplicamos sobre solo los 10 primeros? no entiendop
    #predict(sbp_trans, sbp)
    
    #Dibujamos el histograma de los datos transformados 
    #hist(predict(ldl_trans, ldl))
    #hist(predict(sbp_trans, head(sbp))) 
    #hist(predict(alcohol_trans,alcohol))
    
    # Veamos cómo han cambiado los histogramas de los datos más asimétricos
    t_alcohol <- predict(alcohol_trans,c_alcohol)
    t_tobacco <- predict(tobacco_trans,c_tobacco)
    t_ldl <- predict(ldl_trans, ldl)
    t_sbp <- predict(sbp_trans, sbp)
    
    skewness(t_alcohol)
    skewness(t_tobacco)
    par(mfrow = c(1,2))
    hist(alcohol)
    hist(t_alcohol)
    hist(tobacco)
    hist(t_tobacco)
    hist(ldl)
    hist(t_ldl)
    hist(sbp)
    hist(t_sbp)
    par(mfrow = c(1,1))
```

```{r, echo=F, warning=F}
    
    #Qué hacemos con los que no hemos podido modificar??  <-------------------------- JUANLU
    #Cómo sustituímos ldl y sbp por los modificados
    ldl <- t_ldl
    sbp <- t_sbp
    alcohol <- t_alcohol
    tobacco <- t_tobacco
    
```

```{r, echo=F, warning=F}
    #Paso 4: Eliminación de atributos (en nuestro modelo no hay demasiados (creo))
    pcaObject <- prcomp(sahd,center=TRUE,scale=TRUE)

    # Centros utilizados (?) no lo entiendo  muy bien
    head(pcaObject$center)
    
    #Peso en porcentajes de la varianza de cada atributo
    porcentVariance = pcaObject$sd^2/sum(pcaObject$sd^2)*100
    porcentVariance
    sum(porcentVariance)
    
    # Datos tras rotar y escalar 
    # Cada PCi no sé qué representa
    pcaObject$x
    
    #Atributos junto a su varianza
    plot(pcaObject,type="l")
    
    pcaObject$rotation
    

```

```{r, echo=F, warning=F}
# Realizamos todo el preprocesamiento directamente con preProcess (ejecutando solo el chunk de lectura de datos para hacer esto)

ObjetoTrans = preProcess(sahd[,names(sahd)!="chd"],method = c("BoxCox","center","scale","pca"),thres = 0.8)

# El parámetro thres indica cuántas componentes hacen falta para explicar la fracción thres de los datos
# 1 -> 2 atributos ??????
# 0.95 -> 8 atributos
# 0.9 -> 7 atributos
# 0.8 -> 6 atributos


ObjetoTrans

sahdTrans <- predict(ObjetoTrans,sahd)
dim(sahdTrans)

copy_sahd <- sahd
sahd <- sahdTrans # (Para no cambiar el código siguiente)

```



```{r, echo=F,warning=F}
    
    #Paso 5: Preparación de conjunto de train/test, y de las etiquetas train/test
    train <- sample(nrow(sahd), 0.7*nrow(sahd))
    sahd_train <- sahd[train,-ncol(sahd)]
    sahd_test <- sahd[-train,-ncol(sahd)]
    sahd_label_test <- sahd[-train, 1]#ncol(sahd)]
    sahd_label_train <- sahd[train, 1]#ncol(sahd)]


    #REGRESION LOGISTICA
    #Primer modelo lineal -> Binomial
    ml1 = glm(chd ~ .,family = binomial(logit), data = sahd[,-ncol(sahd)], subset=train)
    summary(ml1)
    
    #Cálculo de probabilidades
    prob_train_ml1 = predict(ml1, type = "response") #no tenemos que introducirle el train porque recuerda
    prob_test_ml1 = predict(ml1, sahd_test, type="response")
    
    #Veamos cómo predice 
    pred_test_ml1 = rep(0, length(prob_test_ml1)) # predicciones por defecto 0
    pred_test_ml1[prob_test_ml1 >=0.5] = 1 # >= 0.5 clase 1
    table(pred_test_ml1, sahd_label_test) 
    
    #obtenemos el E_test
    eval_ml1 = mean(pred_test_ml1 != sahd_label_test)
    cat("Eval con el modelo LR "); print(ml1$call)
    print(eval_ml1)
    
    #obtenemos el E_in
    pred_train_ml1 = rep(0, length(prob_train_ml1)) #predicciones por defecto 0
    pred_train_ml1[prob_train_ml1 >= 0.5] = 1
    table(pred_train_ml1, sahd_label_train)
    
    ein_ml1 = mean(pred_train_ml1 != sahd_label_train)
    cat("E_in con el modelo LR "); print(ml1$call)
    print(ein_ml1)
    
    #El E_in sale mayor que el E_out ?¿?¿?¿?¿
    
    #Segundo modelo lineal -> gaussiana
    #Con todos los atributos
    ml2 = glm(chd ~ .,family = gaussian(identity), data = sahd[,-ncol(sahd)], subset=train)
    summary(ml2)
    
    #Cálculo de probabilidades
    prob_train_ml2 = predict(ml2, type = "response") #no tenemos que introducirle el train porque recuerda
    prob_test_ml2 = predict(ml2, sahd_test, type="response")
    
    #Veamos cómo predice 
    pred_test_ml2 = rep(0, length(prob_test_ml2)) # predicciones por defecto 0
    pred_test_ml2[prob_test_ml2 >=0.5] = 1 # >= 0.5 clase 1
    table(pred_test_ml2, sahd_label_test) 
    
    #obtenemos el E_test
    eval_ml2 = mean(pred_test_ml2 != sahd_label_test)
    cat("Eval con el modelo LR "); print(ml2$call)
    print(eval_ml2)
    
    #obtenemos el E_in
    pred_train_ml2 = rep(0, length(prob_train_ml2)) #predicciones por defecto 0
    pred_train_ml2[prob_train_ml2 >= 0.5] = 1
    table(pred_train_ml2, sahd_label_train)
    
    ein_ml2 = mean(pred_train_ml2 != sahd_label_train)
    cat("E_in con el modelo LR "); print(ml2$call)
    print(ein_ml2)
    
    
    #La Gamam no se puede usar por haber valores negativos  
    
    #Tercer modelo lineal -> 
    ml3 = glm(chd ~ .,family = poisson(log), data = sahd[,-ncol(sahd)], subset=train)
    summary(ml3)
    
    #Cálculo de probabilidades
    prob_train_ml3 = predict(ml3, type = "response") #no tenemos que introducirle el train porque recuerda
    prob_test_ml3 = predict(ml3, sahd_test, type="response")
    
    #Veamos cómo predice 
    pred_test_ml3 = rep(0, length(prob_test_ml3)) # predicciones por defecto 0
    pred_test_ml3[prob_test_ml3 >=0.5] = 1 # >= 0.5 clase 1
    table(pred_test_ml3, sahd_label_test) 
    
    #obtenemos el E_test
    eval_ml3 = mean(pred_test_ml3 != sahd_label_test)
    cat("Eval con el modelo LR "); print(ml3$call)
    print(eval_ml3)
    
    #obtenemos el E_in
    pred_train_ml3 = rep(0, length(prob_train_ml3)) #predicciones por defecto 0
    pred_train_ml3[prob_train_ml3 >= 0.5] = 1
    table(pred_train_ml3, sahd_label_train)
    
    ein_ml3 = mean(pred_train_ml3 != sahd_label_train)
    cat("E_in con el modelo LR "); print(ml3$call)
    print(ein_ml3)
    
```
#Regresión

```{r echo = FALSE}
    #PREPARACIÓN DE LOS DATOS
    ozone <- read.table("./data/ozone", sep=",",head=T)
    summary(ozone)

    #PREPROCESAMIENTO DE LOS DATOS <- Esto hay que hacerlo también en la regresión? No lo tengo claro
    dim(ozone)
    
    #Paso 1: No hay variables cualitativas -> no problemo
    
    #Paso 2: No hay columnas que tengan "Status" ni redundantes (?)
    
    #Paso 3: Eliminación de variables con varianza 0 o muy próximas (importante para métodos sensibles a distancias)
    
    #Paso 4: Eliminación de atributos (en nuestro modelo no hay demasiados (creo))
    
    
    #Paso 5: Preparación de conjunto de train/test
    train_ozone <- sample(nrow(ozone), 0.7*nrow(ozone))
    ozone_train <- ozone[train_ozone,-ncol(ozone)]
    ozone_test <- ozone[-train_ozone,-ncol(ozone)]

    #Ozone es lo que vamos a estimar
    attach(ozone)
    pairs(~ ozone + vh + wind + humidity + temp + ibh + dpg + ibt + vis + doy, data= ozone)
    
    m1 = lm(mpg ~ weight, data=Auto, subset=train)
    
```

