---
title: "Trabajo 3"
author: "Nuria Rodríguez Barroso"
date: "`r format(Sys.time(), '%d de %B de %Y')`"
output: pdf_document
---

```{r echo = FALSE}
    #Fijamos la semilla para obtener siempre los mismos resultados
    set.seed(123456789)
```

#Clasificación.

```{r echo = FALSE, warning=FALSE}
  
    #PREPARACIÓN DE LOS DATOS
    sahd <- read.table("./data/SAHD", sep=",",head=T, row.names = 1)
    summary(sahd)
    
    

    #PREPROCESAMIENTO DE LOS DATOS

    #Paso 1: Modificamos las variables cualitativas (el programa no sabe bien cómo tratarlas)
    #La única variable cualitativa es famhist = {present, absent}
    sahd[,5] <- ifelse(sahd[,5]=='Present',1,0)
    #sahd[,11] <- ifelse(sahd[,5]==1, 0,1) # Tal vez esta sea redundante, porque famhist solo toma dos valores
    colnames(sahd) <- c('sbp', 'tobacco', 'ldl', 'adiposity', 'present_famhist', 'typea', 'obesity', 'alcohol', 'age', 'chd')#, 'absent_famhist')
    #sahd <- sahd[c('sbp', 'tobacco', 'ldl', 'adiposity', 'present_famhist', 'absent_famhist', 'typea', 'obesity', 'alcohol', 'age', 'chd')]
    
    attach(sahd)
    pairs(~ sbp + tobacco + ldl + adiposity + present_famhist +typea + obesity + alcohol + age, data= sahd, col = chd+3)
```

```{r echo = FALSE, warning=FALSE}
    
    #Paso 2: No hay columnas que contengan status ni redundantes

    #Paso 3: Eliminación de variables con varianza 0 o muy próximas (importante para métodos sensibles a distancias)
    library("e1071")
    
    #skewness -> medida de la asimetría de los datos
    skewness(sbp)
    skewness(tobacco)
    skewness(ldl)
    skewness(adiposity)
    skewness(typea)
    skewness(obesity)
    skewness(alcohol)
    skewness(age)
    skewness(present_famhist)
    #skewness(absent_famhist)
    
    #Los datos más asimétricos son -> tobacco y alcohol
    hist(tobacco)
    hist(alcohol)
    
```


```{r, echo=F,warning=F}
    
    #Ordenamos las columnas por asimetria
    sahd_asymmetry <- apply(sahd, 2, skewness)
    sort(abs(sahd_asymmetry), decreasing = T)
    
    #Una vez hemos hallado los datos con asimetría alta, aplicamos la transformación, para ello
    library("caret")
    
    #Lo aplico a los que tienen skewness > 1 ?????
    #BoxCoxTrans no hace la transformación, devuelve el parámetro
    BoxCoxTrans(alcohol) #No se aplica transformación pues no se ha encontrado el parámetro
    BoxCoxTrans(tobacco) #No se aplica transformación pues no se ha encontrado el parámetro
    ldl_trans <- BoxCoxTrans(ldl) #Se aplica transformación con lambda = 0
    sbp_trans <- BoxCoxTrans(sbp) #Lambda estimado -1.8
    
    #Transformamos los datos para los que no se ha encontrado lambda añadiendo una constante
    correction <- 1
    c_alcohol <- alcohol + min(alcohol)+correction
    c_tobacco <- tobacco + min(tobacco)+correction
    alcohol_trans <- BoxCoxTrans(c_alcohol)
    tobacco_trans <- BoxCoxTrans(c_tobacco)
    
    #Aplicamos la transformación a los que han devuelto un lambda
    #predict(ldl_trans, ldl) #Aplicamos sobre solo los 10 primeros? no entiendop
    #predict(sbp_trans, sbp)
    
    #Dibujamos el histograma de los datos transformados 
    #hist(predict(ldl_trans, ldl))
    #hist(predict(sbp_trans, head(sbp))) 
    #hist(predict(alcohol_trans,alcohol))
    
    # Veamos cómo han cambiado los histogramas de los datos más asimétricos
    t_alcohol <- predict(alcohol_trans,c_alcohol)
    t_tobacco <- predict(tobacco_trans,c_tobacco)
    t_ldl <- predict(ldl_trans, ldl)
    t_sbp <- predict(sbp_trans, sbp)
    
    skewness(t_alcohol)
    skewness(t_tobacco)
    par(mfrow = c(1,2))
    hist(alcohol)
    hist(t_alcohol)
    hist(tobacco)
    hist(t_tobacco)
    hist(ldl)
    hist(t_ldl)
    hist(sbp)
    hist(t_sbp)
    par(mfrow = c(1,1))
```

```{r, echo=F, warning=F}
    
    #Qué hacemos con los que no hemos podido modificar??  <-------------------------- JUANLU
    #Cómo sustituímos ldl y sbp por los modificados
    ldl <- t_ldl
    sbp <- t_sbp
    alcohol <- t_alcohol
    tobacco <- t_tobacco
    
```

```{r, echo=F, warning=F}
    #Paso 4: Eliminación de atributos (en nuestro modelo no hay demasiados (creo))
    pcaObject <- prcomp(sahd,center=TRUE,scale=TRUE)

    # Centros utilizados (?) no lo entiendo  muy bien
    head(pcaObject$center)
    
    #Peso en porcentajes de la varianza de cada atributo
    porcentVariance = pcaObject$sd^2/sum(pcaObject$sd^2)*100
    porcentVariance
    sum(porcentVariance)
    
    # Datos tras rotar y escalar 
    # Cada PCi no sé qué representa
    pcaObject$x
    
    #Atributos junto a su varianza
    plot(pcaObject,type="l")
    
    pcaObject$rotation
    

```

```{r, echo=F, warning=F}
# Realizamos todo el preprocesamiento directamente con preProcess (ejecutando solo el chunk de lectura de datos para hacer esto)

ObjetoTrans = preProcess(sahd[,names(sahd)!="chd"],method = c("BoxCox","center","scale","pca"),thres = 0.95)

# El parámetro thres indica cuántas componentes hacen falta para explicar la fracción thres de los datos
# 1 -> 2 atributos ??????
# 0.95 -> 8 atributos
# 0.9 -> 7 atributos
# 0.8 -> 6 atributos


ObjetoTrans

sahdTrans <- predict(ObjetoTrans,sahd)
dim(sahdTrans)



```



```{r, echo=F, warning=F}
  #Paso 5: Preparación de conjunto de train/test, y de las etiquetas train/test
  sahd.data <- sahdTrans[,-1]
  sahd.label <- sahdTrans[,1]
  # sahd.label[sahd.label==0] <- -1  ## (?) Sigue haciendo falta poner labels a -1 y +1 ?
  
  train <- sample(nrow(sahd),0.7*nrow(sahd))
  sahd.train <- sahd.data[train,]
  sahd.test <- sahd.data[-train,]
  
  #Etiquetas
  lsahd.train <- sahd.label[train]
  lsahd.test <- sahd.label[-train]

```


```{r, echo=F,warning=F}
# REGRESIÓN LOGÍSTICA

ml1 <- glm(chd ~ ., family = binomial(logit), data = sahd.data, subset=train)
summary(ml1)

#Cálculo de probabilidades

ml1.prob_train = predict(ml1, type = "response") #no tenemos que introducirle el train porque recuerda
ml1.prob_test = predict(ml1, sahd.test, type="response")

# Etest
ml1.pred_test = rep(0, length(ml1.prob_test)) # predicciones por defecto 0
ml1.pred_test[ml1.prob_test >=0.5] = 1 # >= 0.5 clase 1

table(ml1.pred_test, lsahd.test) 

ml1.Etest = mean(ml1.pred_test != lsahd.test)
cat("Etest con el modelo LR: "); 
print(ml1$call)
print(ml1.Etest)
    
# Ein
ml1.pred_train = rep(0, length(ml1.prob_train)) #predicciones por defecto 0
ml1.pred_train[ml1.prob_train >= 0.5] = 1
table(ml1.pred_train, lsahd.train)
    
ml1.Ein = mean(ml1.pred_train != lsahd.train)
cat("Ein con el modelo LR: "); 
print(ml1$call)
print(ml1.Ein)


```


```{r, echo=F,warning=F}
# GAUSSIANA

ml2 <- glm(chd ~ ., family = gaussian(identity), data = sahd.data, subset=train)
summary(ml2)

#Cálculo de probabilidades

ml2.prob_train = predict(ml2, type = "response") #no tenemos que introducirle el train porque recuerda
ml2.prob_test = predict(ml2, sahd.test, type="response")

# Etest
ml2.pred_test = rep(0, length(ml2.prob_test)) # predicciones por defecto 0
ml2.pred_test[ml2.prob_test >=0.5] = 1 # >= 0.5 clase 1

table(ml2.pred_test, lsahd.test) 

ml2.Etest = mean(ml2.pred_test != lsahd.test)
cat("Etest con el modelo Gaussiano: "); 
print(ml2$call)
print(ml2.Etest)
    
# Ein
ml2.pred_train = rep(0, length(ml2.prob_train)) #predicciones por defecto 0
ml2.pred_train[ml2.prob_train >= 0.5] = 1
table(ml2.pred_train, lsahd.train)
    
ml2.Ein = mean(ml2.pred_train != lsahd.train)
cat("Ein con el modelo Gaussiano: "); 
print(ml2$call)
print(ml2.Ein)


```


<!--
```{r, echo=F,warning=F}
    
    #Paso 5: Preparación de conjunto de train/test, y de las etiquetas train/test
    train <- sample(nrow(sahd), 0.7*nrow(sahd))
    sahd_train <- sahd[train,-ncol(sahd)]
    sahd_test <- sahd[-train,-ncol(sahd)]
    sahd_label_test <- sahd[-train, ncol(sahd)]
    sahd_label_train <- sahd[train, ncol(sahd)]


    #REGRESION LOGISTICA
    #Primer modelo lineal -> Binomial
    ml1 = glm(chd ~ .,family = binomial(logit), data = sahd[,-ncol(sahd)], subset=train)
    summary(ml1)
    
    #Cálculo de probabilidades
    prob_train_ml1 = predict(ml1, type = "response") #no tenemos que introducirle el train porque recuerda
    prob_test_ml1 = predict(ml1, sahd_test, type="response")
    
    #Veamos cómo predice 
    pred_test_ml1 = rep(0, length(prob_test_ml1)) # predicciones por defecto 0
    pred_test_ml1[prob_test_ml1 >=0.5] = 1 # >= 0.5 clase 1
    table(pred_test_ml1, sahd_label_test) 
    
    #obtenemos el E_test
    eval_ml1 = mean(pred_test_ml1 != sahd_label_test)
    cat("Eval con el modelo LR "); print(ml1$call)
    print(eval_ml1)
    
    #obtenemos el E_in
    pred_train_ml1 = rep(0, length(prob_train_ml1)) #predicciones por defecto 0
    pred_train_ml1[prob_train_ml1 >= 0.5] = 1
    table(pred_train_ml1, sahd_label_train)
    
    ein_ml1 = mean(pred_train_ml1 != sahd_label_train)
    cat("E_in con el modelo LR "); print(ml1$call)
    print(ein_ml1)
    
    #El E_in sale mayor que el E_out ?¿?¿?¿?¿
    
    #Segundo modelo lineal -> gaussiana
    #Con todos los atributos
    ml2 = glm(chd ~ .,family = gaussian(identity), data = sahd[,-ncol(sahd)], subset=train)
    summary(ml2)
    
    #Cálculo de probabilidades
    prob_train_ml2 = predict(ml2, type = "response") #no tenemos que introducirle el train porque recuerda
    prob_test_ml2 = predict(ml2, sahd_test, type="response")
    
    #Veamos cómo predice 
    pred_test_ml2 = rep(0, length(prob_test_ml2)) # predicciones por defecto 0
    pred_test_ml2[prob_test_ml2 >=0.5] = 1 # >= 0.5 clase 1
    table(pred_test_ml2, sahd_label_test) 
    
    #obtenemos el E_test
    eval_ml2 = mean(pred_test_ml2 != sahd_label_test)
    cat("Eval con el modelo LR "); print(ml2$call)
    print(eval_ml2)
    
    #obtenemos el E_in
    pred_train_ml2 = rep(0, length(prob_train_ml2)) #predicciones por defecto 0
    pred_train_ml2[prob_train_ml2 >= 0.5] = 1
    table(pred_train_ml2, sahd_label_train)
    
    ein_ml2 = mean(pred_train_ml2 != sahd_label_train)
    cat("E_in con el modelo LR "); print(ml2$call)
    print(ein_ml2)
    
    
    #La Gamam no se puede usar por haber valores negativos  
    
    #Tercer modelo lineal -> 
    ml3 = glm(chd ~ .,family = poisson(log), data = sahd[,-ncol(sahd)], subset=train)
    summary(ml3)
    
    #Cálculo de probabilidades
    prob_train_ml3 = predict(ml3, type = "response") #no tenemos que introducirle el train porque recuerda
    prob_test_ml3 = predict(ml3, sahd_test, type="response")
    
    #Veamos cómo predice 
    pred_test_ml3 = rep(0, length(prob_test_ml3)) # predicciones por defecto 0
    pred_test_ml3[prob_test_ml3 >=0.5] = 1 # >= 0.5 clase 1
    table(pred_test_ml3, sahd_label_test) 
    
    #obtenemos el E_test
    eval_ml3 = mean(pred_test_ml3 != sahd_label_test)
    cat("Eval con el modelo LR "); print(ml3$call)
    print(eval_ml3)
    
    #obtenemos el E_in
    pred_train_ml3 = rep(0, length(prob_train_ml3)) #predicciones por defecto 0
    pred_train_ml3[prob_train_ml3 >= 0.5] = 1
    table(pred_train_ml3, sahd_label_train)
    
    ein_ml3 = mean(pred_train_ml3 != sahd_label_train)
    cat("E_in con el modelo LR "); print(ml3$call)
    print(ein_ml3)
    
```
-->

#Regresión

```{r echo = FALSE}
    #PREPARACIÓN DE LOS DATOS
    ozone.df <- read.table("./data/ozone", sep=",",head=T)
    summary(ozone.df)

    #PREPROCESAMIENTO DE LOS DATOS <- Esto hay que hacerlo también en la regresión? No lo tengo claro
    dim(ozone.df)
    

    #Paso 1: No hay variables cualitativas -> no problemo
    
    #Paso 2: No hay columnas que tengan "Status" ni redundantes (?)
    
    #Paso 3: Eliminación de variables con varianza 0 o muy próximas (importante para métodos sensibles a distancias)
    
    #Paso 4: Eliminación de atributos (en nuestro modelo no hay demasiados (creo))
    

``` 

```{r, echo=F,warning=F}
    #Paso 5: Preparación de conjunto de train/test
    train <- sample(nrow(ozone.df), 0.7*nrow(ozone.df))
    ozone.data <- ozone.df[,-1]
    ozone.label <- ozone.df[,1]
    
    ozone.train <- ozone.data[train,]
    ozone.test <- ozone.data[-train,]
    
    lozone.train <- ozone.label[train]
    lozone.test <- ozone.label[-train]

    #Ozone es lo que vamos a estimar
    attach(ozone.df)
    pairs(~ozone + vh + wind + humidity + temp + ibh + dpg + ibt + vis + doy, data= ozone.df)
    
    mr1 = lm(ozone ~ vh + wind + humidity + temp + ibh + dpg + ibt + vis + doy, data=ozone.df, subset=train)
    
    #Cálulo del Ein
    mr1.Ein <- mean(mr1$residuals^2)
    
    mr1.pred_train = predict(mr1,type = "response")
    mr1.Ein2 <- mean((mr1.pred_train-lozone.train)^2)
    # Salen iguales Ein y Ein2, asi que perfe
    
    #Cálculo del Etest

    mr1.pred_test = predict(mr1, ozone.test, type="response")
    mr1.Etest <- mean((mr1.pred_test-lozone.test)^2)
    
    #plot(doy,ozone, main = "doy vs mpg")
    #abline(m1$coefficients[c(1,10)])
    

```


```{r, echo=F,warning=F}
# Pruebo con una transformación

# Correlaciones aparentes (por el dibujo):
# vh - Potencial e incluso exponencial
# wind - Poca correlación, quizás cuadrática
# humidity - Poca correlación, quizás cuadrática o lineal
# temp - Mucha correlación, lineal o quizás cuadrática
# ibh - Poca correlación
# dpg - Cuadrática
# ibt - Potencial e incluso exponencial
# vis - Poca correlación
# doy - Cuadrática

mr2 = lm(ozone ~ I(exp(vh/6000)) + temp + I(dpg^2) + I(exp(ibt)) + I(doy^2), data=ozone.df, subset=train)

#Cálulo del Ein
    mr2.Ein <- mean(mr2$residuals^2)
    
    #mr2.pred_train = predict(mr2,type = "response")
    #mr2.Ein2 <- mean((mr1.pred_train-lozone.train)^2)
    # Salen iguales Ein y Ein2, asi que perfe
    
    #Cálculo del Etest

    #mr2.pred_test = predict(mr2, ozone.test, type="response")
    #mr2.Etest <- mean((mr2.pred_test-lozone.test)^2)
    

```


```{r, echo=F,warning=F}
# Idea para estimar el comportamiento del ozono respecto a cada dato

# - Elaboramos las tablas (ozono,dato) respecto a cada dato ordenadas por ozono
# - Calculamos el vector de cocientes (ozono[i]-ozono[i-1])/(dato[i]-dato[i-1])
# - Estudiamos el comportamiento del vector cociente

dd <- matrix(ncol = ncol(ozone.df)-1,nrow = nrow(ozone.df)-1)

for(j in 2:ncol(ozone.df)){
  ddm <- matrix(c(ozone,ozone.df[,j]),ncol = 2)
  for(i in 2:nrow(ddm)){
    dd[i-1,j-1] <- (ddm[i,2]-ddm[i-1,2])/(ddm[i,1]-ddm[i-1,1])
  }
}



```

