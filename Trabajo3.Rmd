---
title: "Trabajo 3"
author: "Nuria Rodríguez Barroso"
date: "`r format(Sys.time(), '%d de %B de %Y')`"
output: pdf_document
---

```{r echo = FALSE}
    #Fijamos la semilla para obtener siempre los mismos resultados
    set.seed(123456789)
```

#Clasificación.

## Comprensión del problema a resolver.

```{r echo = FALSE, warning=FALSE}
  
    #PREPARACIÓN DE LOS DATOS
    sahd <- read.table("./data/SAHD", sep=",",head=T, row.names = 1)
    summary(sahd)
    

    #PREPROCESAMIENTO DE LOS DATOS

    #Paso 1: Modificamos las variables cualitativas (el programa no sabe bien cómo tratarlas)
    #La única variable cualitativa es famhist = {present, absent}
    sahd[,5] <- ifelse(sahd[,5]=='Present',1,0)
    colnames(sahd) <- c( 'sbp', 'tobacco', 'ldl', 'adiposity', 'present_famhist', 'typea', 'obesity', 'alcohol', 'age','chd')
    
    attach(sahd)
    pairs(~ sbp + tobacco + ldl + adiposity + present_famhist +typea + obesity + alcohol + age, data= sahd, col = chd+3)
```

## Preprocesado de datos.

```{r echo = FALSE, warning=FALSE}
    
    #Paso 2: No hay columnas que contengan status ni redundantes

    #Paso 3: Eliminación de variables con varianza 0 o muy próximas (importante para métodos sensibles a distancias)
    library("e1071")
    
    #skewness -> medida de la asimetría de los datos
    skewness(sbp)
    skewness(tobacco)
    skewness(ldl)
    skewness(adiposity)
    skewness(typea)
    skewness(obesity)
    skewness(alcohol)
    skewness(age)
    skewness(present_famhist)

    #Los datos más asimétricos son -> tobacco y alcohol
    hist(tobacco)
    hist(alcohol)
    
```


```{r, echo=F,warning=F}
    
    #Ordenamos las columnas por asimetria
    sahd_asymmetry <- apply(sahd, 2, skewness)
    sort(abs(sahd_asymmetry), decreasing = T)
    
    #Una vez hemos hallado los datos con asimetría alta, aplicamos la transformación, para ello
    library("caret")
    
    #Lo aplico a los que tienen skewness > 1 
    #BoxCoxTrans no hace la transformación, devuelve el parámetro
    BoxCoxTrans(alcohol) #No se aplica transformación pues no se ha encontrado el parámetro
    BoxCoxTrans(tobacco) #No se aplica transformación pues no se ha encontrado el parámetro
    ldl_trans <- BoxCoxTrans(ldl) #Se aplica transformación con lambda = 0
    sbp_trans <- BoxCoxTrans(sbp) #Lambda estimado -1.8
    
    #Transformamos los datos para los que no se ha encontrado lambda añadiendo una constante
    correction <- 1
    c_alcohol <- alcohol + min(alcohol)+correction
    c_tobacco <- tobacco + min(tobacco)+correction
    alcohol_trans <- BoxCoxTrans(c_alcohol)
    tobacco_trans <- BoxCoxTrans(c_tobacco)
    
    #Aplicamos la transformación a los que han devuelto un lambda
    #predict(ldl_trans, ldl) #Aplicamos sobre solo los 10 primeros? no entiendop
    #predict(sbp_trans, sbp)
    
    #Dibujamos el histograma de los datos transformados 
    #hist(predict(ldl_trans, ldl))
    #hist(predict(sbp_trans, head(sbp))) 
    #hist(predict(alcohol_trans,alcohol))
    
    # Veamos cómo han cambiado los histogramas de los datos más asimétricos
    t_alcohol <- predict(alcohol_trans,c_alcohol)
    t_tobacco <- predict(tobacco_trans,c_tobacco)
    t_ldl <- predict(ldl_trans, ldl)
    t_sbp <- predict(sbp_trans, sbp)
    
    skewness(t_alcohol)
    skewness(t_tobacco)
    par(mfrow = c(1,2))
    hist(alcohol)
    hist(t_alcohol)
    hist(tobacco)
    hist(t_tobacco)
    hist(ldl)
    hist(t_ldl)
    hist(sbp)
    hist(t_sbp)
    par(mfrow = c(1,1))
```

```{r, echo=F, warning=F}
    
    #Sustituímos los datos que tenían gran asimetría por los transformados
    ldl <- t_ldl
    sbp <- t_sbp
    alcohol <- t_alcohol
    tobacco <- t_tobacco
    
```

```{r, echo=F, warning=F}
    #Paso 4: Eliminación de atributos 
    #center=TRUE -> indicamos que queremos que las variables sean desplazadas de forma que estén centradas en 0.
    #scale=TRUE -> escalar las variables para que tengan varianza 1 antes del análisis.
    pcaObject <- prcomp(sahd,center=TRUE,scale=TRUE)

    # Centros utilizados (?) no lo entiendo  muy bien
    #head(pcaObject$center)
    #Si pones el head te saca solo los 10 primeros
    pcaObject$center

    #Peso en porcentajes de la varianza de cada atributo
    porcentVariance = pcaObject$sd^2/sum(pcaObject$sd^2)*100
    porcentVariance
    sum(porcentVariance)
    
    # Datos tras rotar y escalar 
    # Cada PCi no sé qué representa
    pcaObject$x
    
    #Atributos junto a su varianza
    plot(pcaObject,type="l")
    
    pcaObject$rotation
    

```

```{r, echo=F, warning=F}
# Realizamos todo el preprocesamiento directamente con preProcess (ejecutando solo el chunk de lectura de datos para hacer esto)
#library(caret)

ObjetoTrans = preProcess(sahd[,names(sahd)!="chd"],method = c("BoxCox","center","scale"))

# El parámetro thres indica cuántas componentes hacen falta para explicar la fracción thres de los datos
# 1 -> 2 atributos ??????
# 0.95 -> 8 atributos
# 0.9 -> 7 atributos
# 0.8 -> 6 atributos

#THRES ->  cota del porcentaje de varianza acumulativa retenido por PCA.
ObjetoTrans

sahdTrans <- predict(ObjetoTrans,sahd)
dim(sahdTrans)

```

## Preparación de conjutos de training, validación y test.

```{r, echo=F, warning=F}
  #Paso 5: Preparación de conjunto de train/test, y de las etiquetas train/test
  sahd.data <- sahdTrans[,-ncol(sahdTrans)]
  sahd.label <- sahdTrans[,ncol(sahdTrans)]
  #sahd.label[sahd.label==0] <- -1 
  
  train <- sample(nrow(sahd),0.7*nrow(sahd))
  sahd.train <- sahd.data[train,]
  sahd.test <- sahd.data[-train,]
  
  #Etiquetas
  lsahd.train <- sahd.label[train]
  lsahd.test <- sahd.label[-train]
  
```

## Selección de clases de funciones a usar.

```{r, echo=F,warning=F}
st <- function(ml, test, ltest, s=0){
  #Cálculo de probabilidades
  if(s==0){
    ml.prob_test = predict(ml, test, type="response")

  }else{
    ml.prob_test = predict.glm(ml, test, type = "response",s = s)
    ml.prob_test = ml.prob_test$fit
  }

  # Etest
  ml.pred_test = rep(0, length(ml.prob_test)) # predicciones por defecto 0
  ml.pred_test[ml.prob_test >=0.5] = 1 # >= 0.5 clase 1
  

  ml.Etest = mean(ml.pred_test != ltest)
  
  return(list(ml.Etest, ml.pred_test))
}

calculateEin <- function(ml ,ltrain){
  ml.prob_train = predict(ml, type = "response") #no tenemos que introducirle el train porque recuerda
  # Ein
  ml.pred_train = rep(0, length(ml.prob_train)) #predicciones por defecto 0
  ml.pred_train[ml.prob_train >= 0.5] = 1
    
  ml.Ein = mean(ml.pred_train != ltrain)

  return(list(ml.Ein, ml.pred_train))
}

testFamilies <- function(models, test, ltrain, ltest){

  results <- matrix(nrow=length(models), ncol = 2)
  colnames(results) <- c("Ein","Eout")
  for(i in seq_along(models)){
    results[i,1] <-calculateEin(models[[i]],ltrain)[[1]]
    results[i,2] <- 
      st(models[[i]],test,ltest)[[1]]
  }
  
  return(results)
}
```

```{r, echo=F,warning=F}

# Validación (una sola vez)
validateFamilies <- function(data,label){
  #Muestra
  train <- sample(nrow(data),0.7*nrow(data))
  
  #Datos
  data.train <- data[train,]
  data.test <-  data[-train,]
  
  #Etiquetas
  label.train <- label[train]
  label.test <- label[-train]
  
  #Modelos
  #binomial
  ml.binomial1 <- glm(chd ~ ., family = binomial(logit), data = data, subset=train)
  ml.binomial2 <- glm(chd ~ ., family = binomial(probit), data = data, subset=train)
  ml.binomial3 <- glm(chd ~ ., family = binomial(cauchit), data = data, subset=train)
  #gaussiano
  ml.gaussian1 <- glm(chd ~ ., family = gaussian(identity), data = data, subset=train)
  ml.gaussian2 <- glm(chd ~ ., family = gaussian(log), data = data, subset=train, start=rep(0, ncol(data)+1))
  #poisson
  ml.poisson1 <- glm(chd ~ ., family = poisson(log), data = data, subset=train)
  
  #quasi
  ml.quasi1 <- glm(chd ~ ., family = quasi(link = "identity", variance = "constant"), data = data, subset=train)

  #quasibinomial
  ml.quasibinomial1 <- glm(chd ~ ., family = quasibinomial(link = "logit"), data = data, subset=train)
  #quasipoisson
  ml.quasipoisson1 <- glm(chd ~ ., family = quasipoisson(link = "log"), data = data, subset=train)  

  models <- list(ml.binomial1, ml.binomial2, ml.binomial3, ml.gaussian1, ml.gaussian2, ml.poisson1, ml.quasi1, ml.quasibinomial1, ml.quasipoisson1)
  
  testFamilies(models, data.test, label.train, label.test)
  
}

# Función para realizar multiples validaciones
repValidation <- function(rep,data,label){
  l <- replicate(n = rep, expr = validateFamilies(data,label))
  #l es una matriz 3D de rep x num_modelos x 2 (Ein,Eout)
  #l[,,i] -> experimento i-ésimo
  #[,i,] -> Ein / Eout de cada modelo en los distintos experimentos (i=1 Ein, i=2 Eout)
  #[i,,] -> Ein y Eout para el modelo i-ésimo en cada experimento
  apply(FUN = mean, X = l, MARGIN = c(1,2))
}

```

```{r, echo=F, warning=F}
# Comprobamos qué método proporciona un menor error de validación con múltiples validaciones
repValidation(rep = 100, sahd.data, sahd.label)

# Confirmamos que el modelo que mejor generaliza es el de Poisson
#ml.sahd = ml.poisson1;

```

```{r, echo=F,warning=F}
#Deprecated

# REGRESIÓN LOGÍSTICA

#binomial
ml.binomial1 <- glm(chd ~ ., family = binomial(logit), data = sahd.data, subset=train)
ml.binomial2 <- glm(chd ~ ., family = binomial(probit), data = sahd.data, subset=train)
ml.binomial3 <- glm(chd ~ ., family = binomial(cauchit), data = sahd.data, subset=train)

#gaussiana
ml.gaussian1 <- glm(chd ~ ., family = gaussian(identity), data = sahd.data, subset=train)
ml.gaussian2 <- glm(chd ~ ., family = gaussian(log), data = sahd.data, subset=train, start=rep(0, ncol(sahd.data)+1))
#ml.gaussian3 <- glm(chd ~ ., family = gaussian(inverse), data = sahd.data, subset=train,start=rep(, ncol(sahd.data)+1)) <- no converge
  
#poisson
ml.poisson1 <- glm(chd ~ ., family = poisson(log), data = sahd.data, subset=train)
#ml.poisson2 <- glm(chd ~ ., family = poisson(identity), data = sahd.data, subset=train, start=rep(0,ncol(sahd.data)+1)) 
#ml.poisson1 <- glm(chd ~ ., family = poisson(sqrt), data = sahd.data, subset=train, start=rep(1, ncol(sahd.data)+1))

#quasi
ml.quasi1 <- glm(chd ~ ., family = quasi(link = "identity", variance = "constant"), data = sahd.data, subset=train)

#ml.quasi2 <- glm(chd ~ ., family = quasi(link = "sqrt"), data = sahd.data, subset=train, start=rep(1, ncol(sahd.data)+1)) <- hay mas, todas con el mismo error
  
#quasibinomial
ml.quasibinomial1 <- glm(chd ~ ., family = quasibinomial(link = "logit"), data = sahd.data, subset=train)

#quasipoisson
ml.quasipoisson1 <- glm(chd ~ ., family = quasipoisson(link = "log"), data = sahd.data, subset=train)  

models <- list(ml.binomial1, ml.binomial2, ml.binomial3, ml.gaussian1, ml.gaussian2, ml.poisson1, ml.quasi1, ml.quasibinomial1, ml.quasipoisson1)


  
testFamilies(models, sahd.test, lsahd.train, lsahd.test)

ml.sahd = ml.poisson1;

```

Por tanto, la familia de funciones elegidas es -> la que genera menor Etest -> ml.poisson1 = poisson(log)

## Regularización.

Hay que mirar si hace falta regularización -> ¿Se realiza mucho aprendizaje?

Lasso -> Trata de evitar el sobreaprendizaje penalizando los coeficientes grandes -> Ventaja : además nos simplifica el modelo.

Si suponemos que sí -> R proporciona una función llamada regresión lasso, el funcionamiento consiste en aplicar regresión y cuando los valores están muy cercanos a 0, los trunca directamente a 0.


```{r, echo=F,warning=F}


stReg <-function(datos,label,pesos){
  suma = 0;
   for(i in  1:nrow(datos)){
    aux = sign(datos[i,]%*%pesos)
    if(aux != label[i]){
      suma = suma + 1;
    }
    
  }
  
  return(suma / nrow(datos))
}

```

```{r, echo=F,warning=F}
  #library(glmnet)
  #El método para llamar a GLM con lasso (elasticnet regularization) es glmnet

  #En la documentación aqui parece que haya más families.

  #Mediante validación cruzada sacamos el mejor lambda
  # PREGUNTA: NO SERÍA POISSON????
  ml_lasso <- cv.glmnet(as.matrix(sahd.train), lsahd.train, family="gaussian")

  #Podemos ver los valores y varianzas
  plot(ml_lasso)
  plot(ml_lasso$glmnet.fit, xvar="lambda", label=TRUE)
  #Se puede usar lambda_min o lambda_1se, q es la más grande con varianza más pequeña
  ml_lasso$lambda.min
  ml_lasso$lambda.1se
  
  #Interpretación de los coeficientes -> log hazard ratios, ratio de riesgo.
  #Coeficiente positivo -> alto riesgo de suceso
  #Coeficiente negativo -> viceversa
  #Para q representen la "importancia" -> hay que escalarlos a varianza 1
  #Cuando tiene coeficiente 0 -> la ha quitado del problema (parece q a nosotros no nos quita nada)

  #Utilizamos lambda.1se pues nos quita más atributos.
  coeffs.min <- coef(ml_lasso, s=ml_lasso$lambda.min)
  coeffs.1se <- coef(ml_lasso, s = ml_lasso$lambda.1se)
  
  #Eliminamos los atributos del train  
  coefficients.min <- coeffs.min[1:nrow(coeffs.min),]
  coefficients.1se <- coeffs.1se[1:nrow(coeffs.1se),]
  #sahd.train_lasso = sahd.train[,abs(coefficients)>0]
  #Los eliminamos del test.
  #sahd.test_lasso = sahd.test[,abs(coefficients)>0]
  
  #Aquí hay que hacer otro método del error para calcular el error de coefficients y ver cual es mejor

  st(ml.sahd,sahd.test,lsahd.test,ml_lasso$lambda.min)[[1]]
  
  st(ml.sahd,sahd.test,lsahd.test,ml_lasso$lambda.1se)[[1]]
  
  st(ml.sahd,sahd.test,lsahd.test)[[1]]

```

Parece ser que para un umbral medio pequeño nos quedaríamos con todas, luego no hay que aplicar regularización.

Usando lambda1se si-> Nos elimina 3 características.

## Definición del modelo.

Usar regsubsets

```{r, echo=F,warning=F}
  #nbest -> numero de subconjuntos de cada tamaño para almacenar (que nos devuelva solo el mejor de cada tamaño.)
  #library(leaps)

  #No le quito los atributos porque parece que va a confirmar lo que ya veníamos imaginando: PC2, PC6 y PC7 es caca

  #method = "exhaustive" para que no sea greedy.
  testing <- regsubsets(chd ~ ., data = sahd.data, nbest = 1, method = "exhaustive")

  #Obtenemos una tablita con los que es mejor coger.
  stesting <- summary(testing)
  stesting
  plot(testing)
  
  #Dibujar -> testing$ress
  plot(testing$ress)
  plot(stesting$cp)
  plot(stesting$bic)

  #
  
  
```

## Selección y ajuste del modelo final.


## Estimación del $E_out$.

## Estudio de la calidad del modelo.


#Regresión

```{r echo = FALSE, warning=FALSE}
    #PREPARACIÓN DE LOS DATOS
    ozone.df <- read.table("./data/ozone", sep=",",head=T)
    summary(ozone.df)
    
    dim(ozone.df)
    
    attach(ozone.df)
    pairs( ~ozone + vh + wind + humidity + temp + ibh +dpg + ibt + vis + doy, data= ozone.df, col = ozone+3)
```


    #PREPROCESAMIENTO DE LOS DATOS <- Esto hay que hacerlo también en la regresión? No lo tengo claro
    
```{r, echo=F, warning=F}

#library(caret)

#No aplicamos PCA pues pierde variabilidad.
ObjetoTrans2 = preProcess(ozone.df[,names(ozone.df)!="ozone"],method = c("BoxCox","center","scale"),thres = 0.95)

# El parámetro thres indica cuántas componentes hacen falta para explicar la fracción thres de los datos
# 1 -> 2 atributos ??????
# 0.95 -> 8 atributos
# 0.9 -> 7 atributos
# 0.8 -> 6 atributos

#THRES ->  cota del porcentaje de varianza acumulativa retenido por PCA.
ObjetoTrans2

ozoneTrans <- predict(ObjetoTrans2,ozone.df)
dim(ozoneTrans)

```

## Preparación de conjutos de training, validación y test.

```{r, echo=F, warning=F}
  #Paso 5: Preparación de conjunto de train/test, y de las etiquetas train/test
  ozone.data <- ozoneTrans[,-1]
  ozone.label <- ozoneTrans[,1]
  #sahd.label[sahd.label==0] <- -1 
  
  train <- sample(nrow(ozone.df),0.7*nrow(ozone.df))
  ozone.train <- ozone.data[train,]
  ozone.test <- ozone.data[-train,]
  
  #Etiquetas
  lozone.train <- ozone.label[train]
  lozone.test <- ozone.label[-train]
  
```

## Selección de clases de funciones a usar

lm???? No hay posibilidades de variarlo no? 


## Regularización.


```{r, echo=F,warning=F}
  #library(glmnet)

  #Como estamos usandl lm no le metemos familia?
  mr_lasso <- cv.glmnet(as.matrix(ozone.train), lozone.train)

  #Podemos ver los valores y varianzas
  plot(mr_lasso)
  plot(mr_lasso$glmnet.fit, xvar="lambda", label=TRUE)
  #Se puede usar lambda_min o lambda_1se, q es la más grande con varianza más pequeña
  mr_lasso$lambda.min
  mr_lasso$lambda.1se


  #Utilizamos lambda.1se pues nos quita más atributos.
  coeffs2.min <- coef(mr_lasso, s=mr_lasso$lambda.min)
  coeffs2.1se <- coef(mr_lasso, s=mr_lasso$lambda.1se)
  
  
  #Hay que comprobar qué queda mejor, alguno de estos dos, o el del principio.
  coefficients2.min <- coeffs2.min[2:nrow(coeffs2.min),]
  coefficients2.1se <- coeffs2.1se[2:nrow(coeffs2.1se),]
  
   #Eliminamos los atributos del train  

  #ozone.train = ozone.train[,abs(coefficients)>0]
  #Los eliminamos del test.
  #ozone.test = ozone.test[,abs(coefficients)>0]
```


```{r, echo=F,warning=F}
    
    mr1 = lm(ozone ~ ., ozone.data, train)
    #Cálulo del Ein
    #mr1.Ein2 <- mean(mr1$residuals^2)
    
    mr1.pred_train = predict(mr1,type = "response")
    mr1.Ein <- mean((mr1.pred_train-lozone.train)^2)
    # Salen iguales Ein y Ein2, asi que perfe
    
    #Cálculo del Etest
    mr1.pred_test = predict(mr1, ozone.test, type="response")
    mr1.Etest <- mean((mr1.pred_test-lozone.test)^2)
    
    #plot(doy,ozone, main = "doy vs mpg")
    #abline(m1$coefficients[c(1,10)])
    

```


```{r, echo=F,warning=F}
# Pruebo con una transformación

# Correlaciones aparentes (por el dibujo):
# vh - Potencial e incluso exponencial
# wind - Poca correlación, quizás cuadrática
# humidity - Poca correlación, quizás cuadrática o lineal
# temp - Mucha correlación, lineal o quizás cuadrática
# ibh - Poca correlación
# dpg - Cuadrática
# ibt - Potencial e incluso exponencial
# vis - Poca correlación
# doy - Cuadrática

#Pensar relaciones no cuadráticas.

mr2 = lm(ozone ~ I(vh^2) + temp + I(dpg^2) + I(ibt^2) + I(doy^2), data=ozone.df, subset=train)

#Cálulo del Ein
    mr2.Ein <- mean(mr2$residuals^2)
    
    #Cálculo del Etest
    mr2.pred_test = predict(mr2, ozone.test, type="response")
    mr2.Etest <- mean((mr2.pred_test-lozone.test)^2)
    

```


```{r, echo=F,warning=F}
# Idea para estimar el comportamiento del ozono respecto a cada dato

# - Elaboramos las tablas (ozono,dato) respecto a cada dato ordenadas por ozono
# - Calculamos el vector de cocientes (ozono[i]-ozono[i-1])/(dato[i]-dato[i-1])
# - Estudiamos el comportamiento del vector cociente

dd <- matrix(ncol = ncol(ozone.df)-1,nrow = nrow(ozone.df)-1)

for(j in 2:ncol(ozone.df)){
  ddm <- matrix(c(ozone,ozone.df[,j]),ncol = 2)
  for(i in 2:nrow(ddm)){
    dd[i-1,j-1] <- (ddm[i,2]-ddm[i-1,2])/(ddm[i,1]-ddm[i-1,1])
  }
}


```

