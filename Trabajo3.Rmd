---
title: "Trabajo 3"
author: "Nuria Rodríguez Barroso"
date: "17 de mayo de 2017"
output: pdf_document
---

```{r echo = FALSE}
    #Fijamos la semilla para obtener siempre los mismos resultados
    set.seed(123456789)
```

#Clasificación.

```{r echo = FALSE}
  
    #PREPARACIÓN DE LOS DATOS
    sahd <- read.table("./data/SAHD", sep=",",head=T, row.names = 1)
    summary(sahd)
    
    

    #PREPROCESAMIENTO DE LOS DATOS

    #Paso 1: Modificamos las variables cualitativas (el programa no sabe bien cómo tratarlas)
    #La única variable cualitativa es famhist = {present, absent}
    sahd[,5] <- ifelse(sahd[,5]=='Present',1,0)
    sahd[,11] <- ifelse(sahd[,5]==1, 0,1)
    colnames(sahd) <- c('sbp', 'tobacco', 'ldl', 'adiposity', 'present_famhist', 'typea', 'obesity', 'alcohol', 'age', 'chd', 'absent_famhist')
    sahd <- sahd[c('sbp', 'tobacco', 'ldl', 'adiposity', 'present_famhist', 'absent_famhist', 'typea', 'obesity', 'alcohol', 'age', 'chd')]
    
    attach(sahd)
    pairs(~ sbp + tobacco + ldl + adiposity + present_famhist + absent_famhist +typea + obesity + alcohol + age, data= sahd, col = chd+3)
    
    #Paso 2: No hay columnas que contengan status ni redundantes

    #Paso 3: Eliminación de variables con varianza 0 o muy próximas (importante para métodos sensibles a distancias)
    library("e1071")
    
    #skewness -> medida de la asimetría de los datos
    skewness(sbp)
    skewness(tobacco)
    skewness(ldl)
    skewness(adiposity)
    skewness(typea)
    skewness(obesity)
    skewness(alcohol)
    skewness(age)
    skewness(present_famhist)
    skewness(absent_famhist)
    
    #Los datos más asimétricos son -> tobacco y alcohol
    hist(tobacco)
    hist(alcohol)
    
    #Ordenamos las columnas por asimetria
    sahd_asymmetry <- apply(sahd, 2, skewness)
    sort(abs(sahd_asymmetry), decreasing = T)
    
    #Una vez hemos hallado los datos con asimetría alta, aplicamos la transformación, para ello
    library("caret")
    
    #Lo aplico a los que tienen skewness > 1 ?????
    #BoxCoxTrans no hace la transformación, devuelve el parámetro
    BoxCoxTrans(alcohol) #No se aplica transformación pues no se ha encontrado el parámetro
    BoxCoxTrans(tobacco) #No se aplica transformación pues no se ha encontrado el parámetro
    ldl_trans <- BoxCoxTrans(ldl) #Se aplica transformación con lambda = 0
    sbp_trans <- BoxCoxTrans(sbp) #Lambda estimado -1.8
    
    #Aplicamos la transformación a los que han devuelto un lambda
    #predict(ldl_trans, ldl) #Aplicamos sobre solo los 10 primeros? no entiendop
    #predict(sbp_trans, sbp)
    
    #Dibujamos el histograma de los datos transformados 
    #hist(predict(ldl_trans, head(ldl)))
    #hist(predict(sbp_trans, head(sbp))) 
    
    #Qué hacemos con los que no hemos podido modificar??  <-------------------------- JUANLU
    #Cómo sustituímos ldl y sbp por los modificados
    ldl <- predict(ldl_trans, ldl)
    sbp <- predict(sbp_trans, sbp)
    
    #Paso 4: Eliminación de atributos (en nuestro modelo no hay demasiados (creo))
    
    
    #Paso 5: Preparación de conjunto de train/test, y de las etiquetas train/test
    train <- sample(nrow(sahd), 0.7*nrow(sahd))
    sahd_train <- sahd[train,-ncol(sahd)]
    sahd_test <- sahd[-train,-ncol(sahd)]
    sahd_label_test <- sahd[-train, ncol(sahd)]
    sahd_label_train <- sahd[train, ncol(sahd)]


    #REGRESION LOGISTICA
    #Primer modelo lineal -> Binomial
    ml1 = glm(chd ~ .,family = binomial(logit), data = sahd[,-ncol(sahd)], subset=train)
    summary(ml1)
    
    #Cálculo de probabilidades
    prob_train_ml1 = predict(ml1, type = "response") #no tenemos que introducirle el train porque recuerda
    prob_test_ml1 = predict(ml1, sahd_test, type="response")
    
    #Veamos cómo predice 
    pred_test_ml1 = rep(0, length(prob_test_ml1)) # predicciones por defecto 0
    pred_test_ml1[prob_test_ml1 >=0.5] = 1 # >= 0.5 clase 1
    table(pred_test_ml1, sahd_label_test) 
    
    #obtenemos el E_test
    eval_ml1 = mean(pred_test_ml1 != sahd_label_test)
    cat("Eval con el modelo LR "); print(ml1$call)
    print(eval_ml1)
    
    #obtenemos el E_in
    pred_train_ml1 = rep(0, length(prob_train_ml1)) #predicciones por defecto 0
    pred_train_ml1[prob_train_ml1 >= 0.5] = 1
    table(pred_train_ml1, sahd_label_train)
    
    ein_ml1 = mean(pred_train_ml1 != sahd_label_train)
    cat("E_in con el modelo LR "); print(ml1$call)
    print(ein_ml1)
    
    #El E_in sale mayor que el E_out ?¿?¿?¿?¿
    
    #Segundo modelo lineal -> gaussiana
    #Con todos los atributos
    ml2 = glm(chd ~ .,family = gaussian(identity), data = sahd[,-ncol(sahd)], subset=train)
    summary(ml2)
    
    #Cálculo de probabilidades
    prob_train_ml2 = predict(ml2, type = "response") #no tenemos que introducirle el train porque recuerda
    prob_test_ml2 = predict(ml2, sahd_test, type="response")
    
    #Veamos cómo predice 
    pred_test_ml2 = rep(0, length(prob_test_ml2)) # predicciones por defecto 0
    pred_test_ml2[prob_test_ml2 >=0.5] = 1 # >= 0.5 clase 1
    table(pred_test_ml2, sahd_label_test) 
    
    #obtenemos el E_test
    eval_ml2 = mean(pred_test_ml2 != sahd_label_test)
    cat("Eval con el modelo LR "); print(ml2$call)
    print(eval_ml2)
    
    #obtenemos el E_in
    pred_train_ml2 = rep(0, length(prob_train_ml2)) #predicciones por defecto 0
    pred_train_ml2[prob_train_ml2 >= 0.5] = 1
    table(pred_train_ml2, sahd_label_train)
    
    ein_ml2 = mean(pred_train_ml2 != sahd_label_train)
    cat("E_in con el modelo LR "); print(ml2$call)
    print(ein_ml2)
    
    
    #La Gamam no se puede usar por haber valores negativos  
    
    #Tercer modelo lineal -> 
    ml3 = glm(chd ~ .,family = poisson(log), data = sahd[,-ncol(sahd)], subset=train)
    summary(ml3)
    
    #Cálculo de probabilidades
    prob_train_ml3 = predict(ml3, type = "response") #no tenemos que introducirle el train porque recuerda
    prob_test_ml3 = predict(ml3, sahd_test, type="response")
    
    #Veamos cómo predice 
    pred_test_ml3 = rep(0, length(prob_test_ml3)) # predicciones por defecto 0
    pred_test_ml3[prob_test_ml3 >=0.5] = 1 # >= 0.5 clase 1
    table(pred_test_ml3, sahd_label_test) 
    
    #obtenemos el E_test
    eval_ml3 = mean(pred_test_ml3 != sahd_label_test)
    cat("Eval con el modelo LR "); print(ml3$call)
    print(eval_ml3)
    
    #obtenemos el E_in
    pred_train_ml3 = rep(0, length(prob_train_ml3)) #predicciones por defecto 0
    pred_train_ml3[prob_train_ml3 >= 0.5] = 1
    table(pred_train_ml3, sahd_label_train)
    
    ein_ml3 = mean(pred_train_ml3 != sahd_label_train)
    cat("E_in con el modelo LR "); print(ml3$call)
    print(ein_ml3)
    
```
#Regresión

```{r echo = FALSE}
    #PREPARACIÓN DE LOS DATOS
    ozone <- read.table("./data/ozone", sep=",",head=T)
    summary(ozone)

    #PREPROCESAMIENTO DE LOS DATOS <- Esto hay que hacerlo también en la regresión? No lo tengo claro
    dim(ozone)
    
    #Paso 1: No hay variables cualitativas -> no problemo
    
    #Paso 2: No hay columnas que tengan "Status" ni redundantes (?)
    
    #Paso 3: Eliminación de variables con varianza 0 o muy próximas (importante para métodos sensibles a distancias)
    
    #Paso 4: Eliminación de atributos (en nuestro modelo no hay demasiados (creo))
    
    
    #Paso 5: Preparación de conjunto de train/test
    train_ozone <- sample(nrow(ozone), 0.7*nrow(ozone))
    ozone_train <- ozone[train_ozone,-ncol(ozone)]
    ozone_test <- ozone[-train_ozone,-ncol(ozone)]

    #Ozone es lo que vamos a estimar
    attach(ozone)
    pairs(~ ozone + vh + wind + humidity + temp + ibh + dpg + ibt + vis + doy, data= ozone)
    
    m1 = lm(mpg ~ weight, data=Auto, subset=train)
    
```

