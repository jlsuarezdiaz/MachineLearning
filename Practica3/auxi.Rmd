---
title: "aux"
author: "Nuria Rodríguez Barroso"
date: "26 de mayo de 2017"
output: pdf_document
---


```{r, echo=F,warning=F}
   
    #Una vez hemos hallado los datos con asimetría alta, aplicamos la transformación, para ello

    
    #Lo aplico a los que tienen skewness > 1 
    #BoxCoxTrans no hace la transformación, devuelve el parámetro
    BoxCoxTrans(alcohol) #No se aplica transformación pues no se ha encontrado el parámetro
    BoxCoxTrans(tobacco) #No se aplica transformación pues no se ha encontrado el parámetro
    ldl_trans <- BoxCoxTrans(ldl) #Se aplica transformación con lambda = 0
    sbp_trans <- BoxCoxTrans(sbp) #Lambda estimado -1.8
    
    #Transformamos los datos para los que no se ha encontrado lambda añadiendo una constante
    correction <- 1
    c_alcohol <- alcohol + min(alcohol)+correction
    c_tobacco <- tobacco + min(tobacco)+correction
    alcohol_trans <- BoxCoxTrans(c_alcohol)
    tobacco_trans <- BoxCoxTrans(c_tobacco)
    
    #Aplicamos la transformación a los que han devuelto un lambda
    #predict(ldl_trans, ldl) #Aplicamos sobre solo los 10 primeros? no entiendop
    #predict(sbp_trans, sbp)
    
    #Dibujamos el histograma de los datos transformados 
    #hist(predict(ldl_trans, ldl))
    #hist(predict(sbp_trans, head(sbp))) 
    #hist(predict(alcohol_trans,alcohol))
    
    # Veamos cómo han cambiado los histogramas de los datos más asimétricos
    t_alcohol <- predict(alcohol_trans,c_alcohol)
    t_tobacco <- predict(tobacco_trans,c_tobacco)
    t_ldl <- predict(ldl_trans, ldl)
    t_sbp <- predict(sbp_trans, sbp)
    
    skewness(t_alcohol)
    skewness(t_tobacco)
    par(mfrow = c(1,2))
    hist(alcohol)
    hist(t_alcohol)
    hist(tobacco)
    hist(t_tobacco)
    hist(ldl)
    hist(t_ldl)
    hist(sbp)
    hist(t_sbp)
    par(mfrow = c(1,1))
```

```{r, echo=F, warning=F}
    
    #Sustituímos los datos que tenían gran asimetría por los transformados
    ldl <- t_ldl
    sbp <- t_sbp
    alcohol <- t_alcohol
    tobacco <- t_tobacco
    
```

```{r, echo=F, warning=F}
    #Paso 4: Eliminación de atributos 
    #center=TRUE -> indicamos que queremos que las variables sean desplazadas de forma que estén centradas en 0.
    #scale=TRUE -> escalar las variables para que tengan varianza 1 antes del análisis.
    pcaObject <- prcomp(sahd,center=TRUE,scale=TRUE)

    # Centros utilizados (?) no lo entiendo  muy bien
    #head(pcaObject$center)
    #Si pones el head te saca solo los 10 primeros
    pcaObject$center

    #Peso en porcentajes de la varianza de cada atributo
    porcentVariance = pcaObject$sd^2/sum(pcaObject$sd^2)*100
    porcentVariance
    sum(porcentVariance)
    
    # Datos tras rotar y escalar 
    # Cada PCi no sé qué representa
    pcaObject$x
    
    #Atributos junto a su varianza
    plot(pcaObject,type="l")
    
    pcaObject$rotation
    

```

```{r, echo=F, warning=F}
# Realizamos todo el preprocesamiento directamente con preProcess (ejecutando solo el chunk de lectura de datos para hacer esto)
#library(caret)

ObjetoTrans = preProcess(sahd[,names(sahd)!="chd"],method = c("BoxCox","center","scale"))

# El parámetro thres indica cuántas componentes hacen falta para explicar la fracción thres de los datos
# 1 -> 2 atributos ??????
# 0.95 -> 8 atributos
# 0.9 -> 7 atributos
# 0.8 -> 6 atributos

#THRES ->  cota del porcentaje de varianza acumulativa retenido por PCA.
ObjetoTrans

sahdTrans <- predict(ObjetoTrans,sahd)
dim(sahdTrans)

```

## Preparación de conjutos de training, validación y test.

```{r, echo=F, warning=F}
  #Paso 5: Preparación de conjunto de train/test, y de las etiquetas train/test
  sahd.data <- sahdTrans[,-ncol(sahdTrans)]
  sahd.label <- sahdTrans[,ncol(sahdTrans)]
  #sahd.label[sahd.label==0] <- -1 
  
  train <- sample(nrow(sahd),0.7*nrow(sahd))
  sahd.train <- sahd.data[train,]
  sahd.test <- sahd.data[-train,]
  
  #Etiquetas
  lsahd.train <- sahd.label[train]
  lsahd.test <- sahd.label[-train]
  
```

## Selección de clases de funciones a usar.

```{r, echo=F,warning=F}
calculateEtest <- function(ml, test, ltest, s=0){
  #Cálculo de probabilidades
  if(s==0){
    ml.prob_test = predict(ml, test, type="response")
  }else{
    ml.prob_test = predict(ml,as.matrix(test),type = "response", s = s)
  }

  # Etest
  ml.pred_test = rep(0, length(ml.prob_test)) # predicciones por defecto 0
  ml.pred_test[ml.prob_test >=0.5] = 1 # >= 0.5 clase 1
  

  ml.Etest = mean(ml.pred_test != ltest)
  
  return(list(ml.Etest, ml.pred_test))
}

calculateEin <- function(ml ,ltrain){
  ml.prob_train = predict(ml, type = "response") #no tenemos que introducirle el train porque recuerda
  # Ein
  ml.pred_train = rep(0, length(ml.prob_train)) #predicciones por defecto 0
  ml.pred_train[ml.prob_train >= 0.5] = 1
    
  ml.Ein = mean(ml.pred_train != ltrain)

  return(list(ml.Ein, ml.pred_train))
}

testFamilies <- function(models, test, ltrain, ltest){

  results <- matrix(nrow=length(models), ncol = 2)
  colnames(results) <- c("Ein","Eout")
  for(i in seq_along(models)){
    results[i,1] <-calculateEin(models[[i]],ltrain)[[1]]
    results[i,2] <- 
      calculateEtest(models[[i]],test,ltest)[[1]]
  }
  
  return(results)
}
```

```{r, echo=F,warning=F}

# Validación (una sola vez)
validateFamilies <- function(data,label){
  #Muestra
  train <- sample(nrow(data),0.7*nrow(data))
  
  #Datos
  data.train <- data[train,]
  data.test <-  data[-train,]
  
  #Etiquetas
  label.train <- label[train]
  label.test <- label[-train]
  
  #Modelos
  #binomial
  ml.binomial1 <- glm(chd ~ ., family = binomial(logit), data = data, subset=train)
  ml.binomial2 <- glm(chd ~ ., family = binomial(probit), data = data, subset=train)
  ml.binomial3 <- glm(chd ~ ., family = binomial(cauchit), data = data, subset=train)
  #gaussiano
  ml.gaussian1 <- glm(chd ~ ., family = gaussian(identity), data = data, subset=train)
  ml.gaussian2 <- glm(chd ~ ., family = gaussian(log), data = data, subset=train, start=rep(0, ncol(data)+1))
  #poisson
  ml.poisson1 <- glm(chd ~ ., family = poisson(log), data = data, subset=train)
  
  #quasi
  ml.quasi1 <- glm(chd ~ ., family = quasi(link = "identity", variance = "constant"), data = data, subset=train)

  #quasibinomial
  ml.quasibinomial1 <- glm(chd ~ ., family = quasibinomial(link = "logit"), data = data, subset=train)
  #quasipoisson
  ml.quasipoisson1 <- glm(chd ~ ., family = quasipoisson(link = "log"), data = data, subset=train)  

  models <- list(ml.binomial1, ml.binomial2, ml.binomial3, ml.gaussian1, ml.gaussian2, ml.poisson1, ml.quasi1, ml.quasibinomial1, ml.quasipoisson1)
  
  testFamilies(models, data.test, label.train, label.test)
  
}

# Función para realizar multiples validaciones
repValidation <- function(rep,data,label){
  l <- replicate(n = rep, expr = validateFamilies(data,label))
  #l es una matriz 3D de rep x num_modelos x 2 (Ein,Eout)
  #l[,,i] -> experimento i-ésimo
  #[,i,] -> Ein / Eout de cada modelo en los distintos experimentos (i=1 Ein, i=2 Eout)
  #[i,,] -> Ein y Eout para el modelo i-ésimo en cada experimento
  apply(FUN = mean, X = l, MARGIN = c(1,2))
}

```

```{r, echo=F, warning=F}
# Comprobamos qué método proporciona un menor error de validación con múltiples validaciones
repValidation(rep = 100, sahd.data, sahd.label)

# Confirmamos que el modelo que mejor generaliza es el la gaussiana2
ml.sahd = ml.gaussian2 <- glm(chd ~ ., family = gaussian(log), data = sahd.data, subset=train, start=rep(0, ncol(sahd.data)+1))


```

## Regularización.

Hay que mirar si hace falta regularización -> ¿Se realiza mucho aprendizaje?

Lasso -> Trata de evitar el sobreaprendizaje penalizando los coeficientes grandes -> Ventaja : además nos simplifica el modelo.

Si suponemos que sí -> R proporciona una función llamada regresión lasso, el funcionamiento consiste en aplicar regresión y cuando los valores están muy cercanos a 0, los trunca directamente a 0.




```{r, echo=F,warning=F}
  #library(glmnet)
  #El método para llamar a GLM con lasso (elasticnet regularization) es glmnet

  #En la documentación aqui parece que haya más families.

  #Mediante validación cruzada sacamos el mejor lambda

  testRegularization <- function(data, label, iter = 100){
      error1 <- 0
      error2 <- 0
      error3 <- 0
      
      for(i in 1:iter){
          train <- sample(nrow(data),0.7*nrow(data))
          data.train <- data[train,]
          data.test <- data[-train,]
          #Etiquetas
          ldata.train <- label[train]
          ldata.test <- label[-train]
          
          #Ponemos el link en las etiquetas pues a glmnet no se le puede pasar como argumento
          ml_lasso <- cv.glmnet(as.matrix(data.train), ldata.train, family="gaussian")
          ml = ml.gaussian2 <- glm(chd ~ ., family = gaussian(log), data = data, subset=train, start=rep(0, ncol(data)+1))
    
          error1 <- error1 + calculateEtest(ml_lasso,data.test,ldata.test,ml_lasso$lambda.min)[[1]]
          error2 <- error2 +calculateEtest(ml_lasso,data.test,ldata.test,ml_lasso$lambda.1se)[[1]]
          error3 <- error3 +calculateEtest(ml,data.test,ldata.test)[[1]]
      }
    
      print(error1/100)
      print(error2/100)
      print(error3/100)
  }

  testRegularization(sahd.data, sahd.label, 100)

  
  #ANTIGUO -> PERO PODRIAMOS HACER GRAFICAS Y ESO
  #Podemos ver los valores y varianzas
  #plot(ml_lasso)
  #plot(ml_lasso$glmnet.fit, xvar="lambda", label=TRUE)
  #Se puede usar lambda_min o lambda_1se, q es la más grande con varianza más pequeña
  #ml_lasso$lambda.min
  #ml_lasso$lambda.1se
  
  #Interpretación de los coeficientes -> log hazard ratios, ratio de riesgo.
  #Coeficiente positivo -> alto riesgo de suceso
  #Coeficiente negativo -> viceversa
  #Para q representen la "importancia" -> hay que escalarlos a varianza 1
  #Cuando tiene coeficiente 0 -> la ha quitado del problema (parece q a nosotros no nos quita nada)

  #Utilizamos lambda.1se pues nos quita más atributos.
  #coeffs.min <- coef(ml_lasso, s=ml_lasso$lambda.min)
  #coeffs.1se <- coef(ml_lasso, s = ml_lasso$lambda.1se)
  
  #Eliminamos los atributos del train  
  #coefficients.min <- coeffs.min[1:nrow(coeffs.min),]
  #coefficients.1se <- coeffs.1se[1:nrow(coeffs.1se),]
  #sahd.train_lasso = sahd.train[,abs(coefficients)>0]
  #Los eliminamos del test.
  #sahd.test_lasso = sahd.test[,abs(coefficients)>0]
  



```

Parece ser que para un umbral medio pequeño nos quedaríamos con todas, luego no hay que aplicar regularización.

Usando lambda1se si-> Nos elimina 3 características.

## Definición del modelo.

Usar regsubsets

COMENTARIOS:
1- Como podemos ver en la tabla -> Los atributos que menos aparecen son sbp, adiposity, obesity y alcohol. Justo los que nos eliminaba al aplicar regularización con lambda.1se. Esto es interesting.

2- Obviamente, si dibujamos plot(testing$ress), obtenemos que el error va disminuyendo a medida que usamos más atributos. La idea es hacer un balance entre el número de atributos usados y el error. Para ello utilizamos BIC: https://es.wikipedia.org/wiki/Criterio_de_informaci%C3%B3n_bayesiano.

3- Por tanto, nos quedamos con el número de atributos donde la función BIC alcanza su mínimo (la penalización error/atributos) es menor. Esto es, nos quedamos con 5 atributos que se corresponden (según el esquema obtenido del regsubsets) con: tobacco, ldl, present_famhist, typea y age.

```{r, echo=F,warning=F}
  #nbest -> numero de subconjuntos de cada tamaño para almacenar (que nos devuelva solo el mejor de cada tamaño.)
  #library(leaps)

  #No le quito los atributos porque parece que va a confirmar lo que ya veníamos imaginando: PC2, PC6 y PC7 es caca

  #method = "exhaustive" para que no sea greedy.
  testing <- regsubsets(chd ~ ., data = sahd.data, nbest = 1, method = "exhaustive")

  #Obtenemos una tablita con los que es mejor coger.
  stesting <- summary(testing)
  stesting
  plot(testing)
  
  #Dibujar -> testing$ress
  plot(testing$ress)
  plot(stesting$cp)
  plot(stesting$bic)

  sahd.data <- sahd.data[,c(2,3,5,6,9)]
```


# Transformación de atributos

```{r, echo=F,warning=F}
testPolyTransform <- function(data,label){
  #Muestra
  train <- sample(nrow(data),0.7*nrow(data))
  
  #Datos
  data.train <- data[train,]
  data.test <-  data[-train,]
  
  #Etiquetas
  label.train <- label[train]
  label.test <- label[-train]
  
  #Usamos el modelo ganador
  ml <- glm(chd ~., family = gaussian(log), data = data, subset =train,start=rep(0, ncol(data)+1))
  
  models <- list(ml)
  
  testFamilies(models, data.test, label.train, label.test)
  
}

testPolyTransformRep <- function(rep,data,label){
   l <- replicate(n = rep, expr = testPolyTransform(data,label))
  #l es una matriz 3D de rep x num_modelos x 2 (Ein,Eout)
  #l[,,i] -> experimento i-ésimo
  #[,i,] -> Ein / Eout de cada modelo en los distintos experimentos (i=1 Ein, i=2 Eout)
  #[i,,] -> Ein y Eout para el modelo i-ésimo en cada experimento
  apply(FUN = mean, X = l, MARGIN = c(1,2))
}

# Devuelve un vector de coeficientes para cada atributo
# tol: Nivel de tolerancia: si dos Eout se diferencian en menos de Eout, escogemos el coeficiente más simple
polynomialTransformGreedy <- function(data,label,max_coeff, tol = 0){
  transform <- data
  coeffs <- c()

  for(i in 1:ncol(transform)){
    bestEout <- 1
    bestInd <- 0
    for(j in 1:max_coeff){
      transform[,i] <- I(data[,i])^j
      v <- testPolyTransformRep(100,transform,label)
      # Comparamos con Etest
      if(v[2] + tol < bestEout){
        bestEout <- v[2]
        bestInd <- j
      }
      cat("Attr = ",i,", Exp = ",j,", Eout = ",v[2],"\n")
    }
    #Nos quedamos con el mejor coeficiente obtenido para el atributo
    transform[,i] <- I(data[,i])^bestInd
    coeffs <- c(coeffs,bestInd)
  }
  # Por ser greedy con el mecanismo escogido el mejor Eout va a ser el de la última iteración
  list(coeffs,bestEout)
}
```

```{r, echo=F,warning=F}
polynomialTransformGreedy(sahd.data,sahd.label,4, tol = 0.01)

```

## Selección y ajuste del modelo final.


## Estimación del $E_out$.

## Estudio de la calidad del modelo.


#Regresión

```{r echo = FALSE, warning=FALSE}
    #PREPARACIÓN DE LOS DATOS
    ozone.df <- read.table("./data/ozone", sep=",",head=T)
    summary(ozone.df)
    
    dim(ozone.df)
    
    attach(ozone.df)
    #pairs( ~ozone + vh + wind + humidity + temp + ibh +dpg + ibt + vis + doy, data= ozone.df, col = "blue")
```


    #PREPROCESAMIENTO DE LOS DATOS <- Esto hay que hacerlo también en la regresión? No lo tengo claro
    
```{r, echo=F, warning=F}

#library(caret)

#No aplicamos PCA pues pierde variabilidad.
ObjetoTrans2 = preProcess(ozone.df[,names(ozone.df)!="ozone"],method = c("BoxCox","center","scale"))

# El parámetro thres indica cuántas componentes hacen falta para explicar la fracción thres de los datos
# 1 -> 2 atributos ??????
# 0.95 -> 8 atributos
# 0.9 -> 7 atributos
# 0.8 -> 6 atributos

#THRES ->  cota del porcentaje de varianza acumulativa retenido por PCA.
ObjetoTrans2

ozoneTrans <- predict(ObjetoTrans2,ozone.df)
dim(ozoneTrans)

```

Volvemos a comparar todas las gráficas d parejas de atributos tras preprocesar los datos.

```{r,echo=F,warning=F}

attach(ozoneTrans)
pairs( ~ozone + vh + wind + humidity + temp + ibh +dpg + ibt + vis + doy, data= ozoneTrans, col = "blue")
```

Comparando con la gráfica anterior comprobamos que, aunque los datos se hayan escalado, la forma en la que se distribuyen los datos sigue siendo la misma.

## Preparación de conjutos de training, validación y test.

```{r, echo=F, warning=F}
  #Paso 5: Preparación de conjunto de train/test, y de las etiquetas train/test
  ozone.data <- ozoneTrans[,-1]
  ozone.label <- ozoneTrans[,1]
  #sahd.label[sahd.label==0] <- -1 
  
  train <- sample(nrow(ozone.df),0.7*nrow(ozone.df))
  ozone.train <- ozone.data[train,]
  ozone.test <- ozone.data[-train,]
  
  #Etiquetas
  lozone.train <- ozone.label[train]
  lozone.test <- ozone.label[-train]
  
```

## Selección de clases de funciones a usar

```{r, echo=F,warning=F}
calculateEtestRegression <- function(mr, test, ltest, s = 0){
    if(s==0){
      mr.pred_test = predict(mr, test, type="response")
    }else{
      mr.pred_test = predict(mr,as.matrix(test),type = "response", s = s)
    }
    #mr.pred_test = predict(mr, test, type="response")
    mr.Etest <- mean((mr.pred_test-ltest)^2)
    
    return(list(mr.Etest,mr.pred_test))
}

calculateEinRegression <- function(mr ,ltrain){
    mr.pred_train = predict(mr,type = "response")
    mr.Ein <- mean((mr.pred_train-ltrain)^2)

    return(list(mr.Ein, mr.pred_train))
}

testFamiliesRegression <- function(models, test, ltrain, ltest){

  results <- matrix(nrow=length(models), ncol = 2)
  colnames(results) <- c("Ein","Eout")
  for(i in seq_along(models)){
    results[i,1] <-calculateEinRegression(models[[i]],ltrain)[[1]]
    results[i,2] <- 
      calculateEtestRegression(models[[i]],test,ltest)[[1]]
  }
  
  return(results)
}
```

```{r, echo=F,warning=F}

# Validación (una sola vez)
validateFamiliesRegression <- function(data,label){
  #Muestra
  train <- sample(nrow(data),0.7*nrow(data))
  
  #Datos
  data.train <- data[train,]
  data.test <-  data[-train,]
  
  #Etiquetas
  label.train <- label[train]
  label.test <- label[-train]
  
  #Modelos
  mr1 = lm(ozone ~ ., data, train)


  models <- list(mr1)
  
  testFamiliesRegression(models, data.test, label.train, label.test)
  
}

# Función para realizar multiples validaciones
repValidationRegression <- function(rep,data,label){
  l <- replicate(n = rep, expr = validateFamiliesRegression(data,label))
  #l es una matriz 3D de rep x num_modelos x 2 (Ein,Eout)
  #l[,,i] -> experimento i-ésimo
  #[,i,] -> Ein / Eout de cada modelo en los distintos experimentos (i=1 Ein, i=2 Eout)
  #[i,,] -> Ein y Eout para el modelo i-ésimo en cada experimento
  apply(FUN = mean, X = l, MARGIN = c(1,2))
}

```


```{r, echo=F,warning=F}
  repValidationRegression(100,ozone.data,ozone.label)
```



## Regularización.


```{r, echo=F,warning=F}

testRegularizationRegression <- function(data, label, iter = 100){
      error1 <- 0
      error2 <- 0
      error3 <- 0
      
      for(i in 1:iter){
          train <- sample(nrow(data),0.7*nrow(data))
          data.train <- data[train,]
          data.test <- data[-train,]
          #Etiquetas
          ldata.train <- label[train]
          ldata.test <- label[-train]
          
          #Ponemos el link en las etiquetas pues a glmnet no se le puede pasar como argumento
          #grid=10^seq(10,-2,length=100)
          ml_lasso <- cv.glmnet(as.matrix(data.train), ldata.train)
          ml = lm(ozone ~ ., data, train)
    
          error1 <- error1 + calculateEtestRegression(ml_lasso,data.test,ldata.test,ml_lasso$lambda.min)[[1]]
          error2 <- error2 +calculateEtestRegression(ml_lasso,data.test,ldata.test,ml_lasso$lambda.1se)[[1]]
          error3 <- error3 +calculateEtestRegression(ml,data.test,ldata.test)[[1]]
      }
    
      print(error1/iter)
      print(error2/iter)
      print(error3/iter)
  }
```

```{r, echo=F,warning=F}
  #library(glmnet)


  testRegularizationRegression(ozone.data, ozone.label, 100)

  #Como el error ha disminuido usando lambda.min
  grid=10^seq(10,-2,length=100)
  mr_lasso <- cv.glmnet(as.matrix(data.train), ldata.train, lambda = grid)
  best_lambda = mr_lasso$lambda.min
  

```

```{r, echo=F,warning=F}
  #nbest -> numero de subconjuntos de cada tamaño para almacenar (que nos devuelva solo el mejor de cada tamaño.)
  #library(leaps)

  #No le quito los atributos porque parece que va a confirmar lo que ya veníamos imaginando: PC2, PC6 y PC7 es caca

  #method = "exhaustive" para que no sea greedy.
  testing <- regsubsets(ozone ~ ., data = ozone.data, nbest = 1, method = "exhaustive")

  #Obtenemos una tablita con los que es mejor coger.
  stesting <- summary(testing)
  stesting
  plot(testing)
  
  #Dibujar -> testing$ress
  plot(testing$ress)
  plot(stesting$cp)
  plot(stesting$bic)
  
  ozone.data <- ozone.data[c(3,4,5,7,8,9)]

```

## Transformación de atributos

```{r, echo=F,warning=F}
testPolyTransformRegression <- function(data,label){
  #Muestra
  train <- sample(nrow(data),0.7*nrow(data))
  
  #Datos
  data.train <- data[train,]
  data.test <-  data[-train,]
  
  #Etiquetas
  label.train <- label[train]
  label.test <- label[-train]
  
  #Usamos el modelo ganador
  mr <- lm(ozone ~ ., data, train)
  
  models <- list(mr)
  
  testFamiliesRegression(models, data.test, label.train, label.test)
  
}

testPolyTransformRepReg <- function(rep,data,label){
   l <- replicate(n = rep, expr = testPolyTransformRegression(data,label))
  #l es una matriz 3D de rep x num_modelos x 2 (Ein,Eout)
  #l[,,i] -> experimento i-ésimo
  #[,i,] -> Ein / Eout de cada modelo en los distintos experimentos (i=1 Ein, i=2 Eout)
  #[i,,] -> Ein y Eout para el modelo i-ésimo en cada experimento
  apply(FUN = mean, X = l, MARGIN = c(1,2))
}

# Devuelve un vector de coeficientes para cada atributo
# tol: Nivel de tolerancia: si dos Eout se diferencian en menos de Eout, escogemos el coeficiente más simple
polynomialTransformGreedyRegression <- function(data,label,max_coeff, tol = 0){
  transform <- data
  coeffs <- c()

  for(i in 1:ncol(transform)){
    bestEout <- Inf
    bestInd <- 0
    for(j in 1:max_coeff){
      transform[,i] <- I(data[,i]^j)
      v <- testPolyTransformRepReg(100,transform,label)
      # Comparamos con Etest
      if(v[2] + tol < bestEout){
        bestEout <- v[2]
        bestInd <- j
      }
      cat("Attr = ",i,", Exp = ",j,", Eout = ",v[2],"\n")
    }
    #Nos quedamos con el mejor coeficiente obtenido para el atributo
    transform[,i] <- I(data[,i]^bestInd)
    coeffs <- c(coeffs,bestInd)
  }
  # Por ser greedy con el mecanismo escogido el mejor Eout va a ser el de la última iteración
  list(coeffs,bestEout)
}
```

```{r, echo=F,warning=F}
l <- polynomialTransformGreedyRegression(ozone.data,ozone.label,4, tol = 0.01)

cat("Vector de exponentes: ", l[[1]])
cat("Eout estimado: ",l[[2]])

```


```{r, echo=F,warning=F}
    
    mr1 = lm(ozone ~ ., ozone.data, train)
    #Cálulo del Ein
    #mr1.Ein2 <- mean(mr1$residuals^2)
    
    mr1.pred_train = predict(mr1,type = "response")
    mr1.Ein <- mean((mr1.pred_train-lozone.train)^2)
    # Salen iguales Ein y Ein2, asi que perfe
    
    #Cálculo del Etest
    mr1.pred_test = predict(mr1, ozone.test, type="response")
    mr1.Etest <- mean((mr1.pred_test-lozone.test)^2)
    
    #plot(doy,ozone, main = "doy vs mpg")
    #abline(m1$coefficients[c(1,10)])
    mr1.Ein
    mr1.Etest

```

```{r, echo=F,warning=F}
# Pruebo con una transformación

# Correlaciones aparentes (por el dibujo):
# vh - Potencial e incluso exponencial
# wind - Poca correlación, quizás cuadrática
# humidity - Poca correlación, quizás cuadrática o lineal
# temp - Mucha correlación, lineal o quizás cuadrática
# ibh - Poca correlación
# dpg - Cuadrática
# ibt - Potencial e incluso exponencial
# vis - Poca correlación
# doy - Cuadrática

#Pensar relaciones no cuadráticas.

mr2 = lm(ozone ~ I(vh^2) + temp + I(dpg^2) + I(ibt^2) + I(doy^2), data=ozone.df, subset=train)

#Cálulo del Ein
    mr2.Ein <- mean(mr2$residuals^2)
    
    #Cálculo del Etest
    mr2.pred_test = predict(mr2, ozone.test, type="response")
    mr2.Etest <- mean((mr2.pred_test-lozone.test)^2)
    
mr2.Ein
mr2.Etest

```



```{r, echo=F,warning=F}
x1 <- c(1:100,1:100)
x2 <- 1:200
x2[1:100] <- (x1[1:100])^2-1
x2[101:200]<- (x1[101:200])^2+1

y <- sign(x2-x1^2)
y[y==-1] <- 0

prueba.data <- matrix(c(x1,x2,y),ncol = 3)
colnames(prueba.data) <- c("x1","x2","y")

plot(x1,x2, col = y +3)

validateFamilies(prueba.data,y)
train <- sample(nrow(prueba.data), 0.7*nrow(prueba.data))

ml.binomial1 <- glm(y ~ ., family = gaussian(identity), data = as.data.frame(prueba.data), subset=train)

calculateEin(ml.binomial1,y[train])

ml.binomial1$coefficients

```

```{r, echo=F,warning=F}
pairs( ~ tobacco + ldl + present_famhist + typea + age, data=sahd.data, col = chd+3)
  #Paso 5: Preparación de conjunto de train/test, y de las etiquetas train/test
  sahd.data <- sahdTrans[,-ncol(sahdTrans)]
  sahd.label <- sahdTrans[,ncol(sahdTrans)]
  #sahd.label[sahd.label==0] <- -1 
  
  train <- sample(nrow(sahd),0.7*nrow(sahd))
  sahd.train <- sahd.data[train,]
  sahd.test <- sahd.data[-train,]
  
  #Etiquetas
  lsahd.train <- sahd.label[train]
  lsahd.test <- sahd.label[-train]
  
  ml <- glm(chd ~ ldl+age+I(ldl^2)+I(age^2)+I(age*ldl) , family = poisson(log), data = sahd.data, subset=train)
  
  ml$coefficients
  
#  calculateEtest <- function(ml, test, ltest, s=0){
#  #Cálculo de probabilidades
#  if(s==0){
#    ml.prob_test = predict(ml, test, type="response")
#  }else{
#    ml.prob_test = predict(ml,as.matrix(test),type = "response", s = s)
#  }

  # Etest
#  ml.pred_test = rep(0, length(ml.prob_test)) # predicciones por defecto 0
#  ml.pred_test[ml.prob_test >=0.5] = 1 # >= 0.5 clase 1
  

#  ml.Etest = mean(ml.pred_test != ltest)
  
#  return(list(ml.Etest, ml.pred_test))
#}

#calculateEin <- function(ml ,ltrain){
#  ml.prob_train = predict(ml, type = "response") #no tenemos que introducirle el train porque recuerda
#  # Ein
#  ml.pred_train = rep(0, length(ml.prob_train)) #predicciones por defecto 0
#  ml.pred_train[ml.prob_train >= 0.5] = 1
    
#  ml.Ein = mean(ml.pred_train != ltrain)

#  return(list(ml.Ein, ml.pred_train))
#}
  
ml.probtrain <- predict(ml.sahd,type="response")
ml.predtrain <- rep(0,length(ml.probtrain))
ml.predtrain[ml.probtrain >= 0.5]=1
ml.Etrain = mean(ml.predtrain != lsahd.train)
  
ml.probtest <- predict(ml,sahd.test,type="response")
ml.predtest <- rep(0,length(ml.probtest))
ml.predtest[ml.probtest >= 0.5]=1
ml.Etest = mean(ml.predtest != lsahd.test)
ml.Etest

```
