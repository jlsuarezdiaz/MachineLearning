---
title: "Trabajo 3: AJUSTE DE MODELOS LINEALES"
author: "Nuria Rodríguez Barroso, Juan Luis Suárez Díaz."
date: "`r format(Sys.time(), '%d de %B de %Y')`"
output: pdf_document
toc: yes
---

\clearpage

```{r, echo = FALSE, warnings = FALSE, results = FALSE, message = FALSE}
    #Fijamos la semilla para obtener siempre los mismos resultados
    set.seed(3928423)

    #Añadimos librerías necesarias.
    library("caret")
    library("e1071")
    library("glmnet")
    library("leaps")

```

#Clasificación.

## Comprensión del problema a resolver.

Para el problema de clasificación hemos elegido la base de datos de *South African Heart Disease*, que almacena una muestra recapituladora de hombres en alto riesgo de cardiopatía en la región de Western Cape, en Sudáfrica. Hay dos casos de CHD (0 o 1). Algunos de los hombres que tienen CHD positivo, se han sometido a un tratamiento de reducción de la presión sanguínea, siendo los datos que aparecen en la muestra posteriores a estos tratamientos. Estos datos datan de 1983.

Nuestra base de datos consta de 462 muestras donde cada una de ellas cuenta con 10 atributos, uno de ellos la variable de respuesta. Los diferentes atributos a tratar son:

- **sbp:** presión arterial sistólica. Toma valores entre 101 y 218, siendo la media 138.3. 
- **tobacco:** tabaco acumulativo (en kg). Toma como valor mínimo 0 y máximo 31.2. En este caso la media es de 3.6356.
- **ldl:** lipoproteína de baja densidad (colesterol). Toma valores entre 0.98 y 15.330, siendo la media 4.74.
- **adiposidad:** Tomando valores entre 6.74 y 42.49, siendo la media de los valores 25.41.
- **famhist:** historial familiar de cardiopatías. Toma como valores \{Present, Absent\}, habiendo del primer tipo 270 y del segundo 192.
- **typea:** Personalidad Tipo-A (mide el grado de estrés en el día a día). Toma valores entre 13 y 78, siendo la media 53.1.
- **obesity:** Obesidad. Toma valores entre 14.7 y 46.58, siendo la media 26.04.
- **alcohol:** Actual consumición de alcohol. Toma valores entre 0 y 147.19, encontrándose el valor medio en 17.04.
- **age:** Edad de los hombres al comienzo de las pruebas. Se encuentra entre 15 y 64 años, siendo la edad media 42.82.
- **chd:** Variable de respuesta, indica si se tiene o no alguna cardiopatía. Toma como valores \{0,1\}, siendo la media 0.3463.

```{r, echo = FALSE, warning=FALSE, results= FALSE, message = FALSE}
  
    #PREPARACIÓN DE LOS DATOS
    sahd <- read.table("./data/SAHD", sep=",",head=T, row.names = 1)
    summary(sahd)

```

## Preprocesado de datos.

Como podemos observar en el breve estudio de los diferentes atributos que vamos a trabajar, cada uno toma valores en una franja muy diferente, lo que hace primar unos atributos sobre otros en los métodos basados en distancias. Además, algunos atributos presentan una gran asimetría, lo cual también es conveniente evitar. Por estos motivos y otros más que estudiaremos a continuación, tenemos que preprocesar los datos.

### Modificación de los atributos cualitativos.
Tenemos que convertir los atributos cualitativos en atributos numéricos para que las funciones que usemos más adelante puedan trabajar con ellos. En nuestro problema concreto, solo contamos con un atributo cualitativo: *famhist*, que toma los valores \{Present, Absent\}. Convertimos este atributo en el atributo *present_famhist*, que tomará el valor 1, cuando *famhist* tomaba el valor Present y 0 en el otro caso. Así, el atributo *present_famhist* tomará valores en \{0,1\}.

```{r echo = FALSE, warning=FALSE, results = FALSE, message = FALSE}

    #PREPROCESAMIENTO DE LOS DATOS

    #Paso 1: Modificamos las variables cualitativas (el programa no sabe bien cómo tratarlas)
    #La única variable cualitativa es famhist = {present, absent}
    sahd[,5] <- ifelse(sahd[,5]=='Present',1,0)
    colnames(sahd) <- c( 'sbp', 'tobacco', 'ldl', 'adiposity', 'present_famhist', 'typea', 'obesity', 'alcohol', 'age','chd')
    
    #Para ir explicando una a una las transformaciones
    sahd_aux <- sahd
    
    attach(sahd_aux)
    #pairs(~ sbp + tobacco + ldl + adiposity + present_famhist +typea + obesity + alcohol + age, data= sahd, col = chd+3)
```

Para el resto de pasos, utilizaremos una función llamada *preProcess()*, la cual terminará con el preprocesado de los datos. Esta función realizará los siguientes cambios:

### Tratamiento de la asimetría con BoxCox.

Como ya hemos comentado anteriormente, hay varios atributos que presentan una alta asimetría, lo cual podría hacer que los métodos de predicción que apliquemos a continuación obtengan resultados peores. Para solucionar esto, utilizaremos un método llamado BoxCox. Este método se basa en la transformación potencial según un valor ($\lambda$) para aumentar la correlación entre las variables. Para elegir la mejor potencia (mejor $\lambda$), se busca entre los $\lambda$ que proporcionen un menor error residual. Aunque en la práctica, esto se realizará de manera automátcica con la función *preProcess()* vamos a ver cómo funciona en el caso de un atributo. 
Para que se vea mejor el funcionamiento, vamos a elegir el atributo que presente una mayor asimetría. Para ello, ordenamos los atributos en función de su asimetría:


```{r, echo=F,warning=F}
    #Eliminación de variables con varianza 0 o muy próximas (importante para métodos sensibles a distancias)
   
   #Ordenamos las columnas por asimetria
    sahd_asymmetry <- apply(sahd_aux, 2, skewness)
    sahd_asymmetry <- sort(abs(sahd_asymmetry), decreasing = T)
    print(sahd_asymmetry)
    
```

Si dibujamos el histograma correspondiente al atributo con mayor asimetría, *alcohol* corroboramos que los datos se encuentran muy concentrados en los primeros valores que este atributo toma.

```{r, echo=F,warning=F}
    hist(alcohol, col = "blue")
```

Vamos a aplicar ahora el método *BoxCox* y veremos cómo mejora la simetría del atributo.

```{r, echo=F,warning=F}
    BoxCoxTrans(alcohol) #No se aplica transformación pues no se ha encontrado el parámetro
```

Como observamos, no se encuentra un $\lambda$ válido para realizar la transformación, y esto se debe a que entre los valores que toma el atributo se encuentra el 0, punto en el cual no está definida la función logaritmo. Para solucionar esto, realizamos una translación de los datos de la forma: datos = min(datos) + 1 + datos, para así conseguir que el mínimo de los datos se desplace a 1. Tras realizar esta transformación obtenemos:

```{r, echo=F,warning=F}
  correction <- 1
  c_alcohol <- alcohol + min(alcohol)+correction
  alcohol_trans <- BoxCoxTrans(c_alcohol)
  t_alcohol <- predict(alcohol_trans,c_alcohol)
  
  print("La asimetría del alcohol transformado es:")
  print(skewness(t_alcohol))
  
  par(mfrow = c(1,2))
  hist(alcohol, col = "red")
  hist(t_alcohol, col = "green")
  par(mfrow = c(1,1))
    
```

Para aplicar esta transformación a todos los atributos con el $\lambda$ correspondiente, pasaremos como parámetro al método $preProcess$ que realice el método $BoxCox$ y todo esto se hará de forma automática.

### Eliminación de atributos con PCA.

El algoritmo PCA (Principal Components Analysis) es un filtro no supervisado que es de gran utilidad cuando disponemos de una base de datos con un gran número de atributos, entre los que algunos pueden ser redundantes o irrelevantes. Como nuestra base de datos solo consta de 10 atributos, no es necesaria la aplicación de este método.

### Centrar y escalar.


También es conveniente centrar y escalar las variables para que no prioricen unas sobre otras, dado que puede ser útil en algunos métodos que utilizaremos más adelante. Al escalar una variable lo que se está haciendo es dividir cada dato entre la desviación típica del conjunto de datos, transformando así el conjunto de datos en un conjunto de varianza 1. En cuanto a centrar el conjunto de datos, lo que se hace es restar a cada dato la media del conjunto, transformándolo así en un conjunto de media 0. Al escalar y centrar a la vez, estamos aplicando la transformación $X \leftarrow (X-\mu)/\sigma$, normalizando así el conjunto a un conjunto de media 0 y varianza 1. Esto nos permite tener los atributos normalizados, y además manteniendo las mismas distribuciones entre los distintos atributos, como veremos más adelante en la regresión. El método *preProcess* se encargará de centrar las variables en 0 y de escalar las variables para tener varianza unitaria. Para ello, bastaría con pasar como argumento *scale* y *center* cuando llamemos al método *preProcess*.


### Llamada al método PreProcess.

Una vez entendidas las modificaciones que vamos a realizar a los datos, utilizaremos el método preProcess que se encarga de realizar todas estas modificaciones sobre el conjunto de datos pasado como argumento. Como ya hemos comentado, no vamos a aplicar el método *PCA*, luego la llamada quedaría de la siguiente forma:

```{r, echo=T, warning=F}

ObjetoTrans = preProcess(sahd[,names(sahd)!="chd"],method = c("BoxCox","center","scale"))
sahdTrans <- predict(ObjetoTrans,sahd)

```

## Conjuntos de validación, training y test usados.

A continuación pasaremos a explorar los distintos modelos sobre los que resolver el problema de clasificación para nuestro conjunto de datos. El procedimiento de validación que usaremos consistirá en tomar múltiples veces distintos conjuntos de entrenamiento sobre nuestro conjunto de datos (una vez transformados), con los que aprenderemos el modelo. Usaremos el resto del conjunto como test para evaluar cómo de bien predice el modelo aprendido con nuevos datos. Las proporciones utilizadas serán del 70 % de los datos para train, y el 30 % para test.

```{r, echo=F, warning=F}
  #Paso 5: Preparación de conjunto de train/test, y de las etiquetas train/test
  sahd.data <- sahdTrans[,-ncol(sahdTrans)]
  sahd.label <- sahdTrans[,ncol(sahdTrans)]
  #sahd.label[sahd.label==0] <- -1 
  
  
  train <- sample(nrow(sahd),0.7*nrow(sahd))
  sahd.train <- sahd.data[train,]
  sahd.test <- sahd.data[-train,]
  
  #Etiquetas
  lsahd.train <- sahd.label[train]
  lsahd.test <- sahd.label[-train]
  
```



```{r, echo=F,warning=F}
# Funciones para el cálculo del error
calculateEtest <- function(ml, test, ltest, s=0){
  #Cálculo de probabilidades
  if(s==0){
    ml.prob_test = predict(ml, test, type="response")
  }else{
    ml.prob_test = predict(ml,as.matrix(test),type = "response", s = s)
  }

  # Etest
  ml.pred_test = rep(0, length(ml.prob_test)) # predicciones por defecto 0
  ml.pred_test[ml.prob_test >=0.5] = 1 # >= 0.5 clase 1
  

  ml.Etest = mean(ml.pred_test != ltest)
  
  return(list(ml.Etest, ml.pred_test))
}

calculateEin <- function(ml ,ltrain){
  ml.prob_train = predict(ml, type = "response") #no tenemos que introducirle el train porque recuerda
  # Ein
  ml.pred_train = rep(0, length(ml.prob_train)) #predicciones por defecto 0
  ml.pred_train[ml.prob_train >= 0.5] = 1
    
  ml.Ein = mean(ml.pred_train != ltrain)

  return(list(ml.Ein, ml.pred_train))
}

# Función para evaluar loserrores para un conjunto de modelos.
# Argumentos:
# models - lista de modelos
# test - conjunto de test
# ltrain - etiquetas de train
# ltest - etiquetas de test
# Devuelve: Matriz de num_modelos x 2. Las columnas representan (Ein, Etest)
testFamilies <- function(models, test, ltrain, ltest){

  results <- matrix(nrow=length(models), ncol = 2)
  colnames(results) <- c("Ein","Eout")
  for(i in seq_along(models)){
    results[i,1] <-calculateEin(models[[i]],ltrain)[[1]]
    results[i,2] <- 
      calculateEtest(models[[i]],test,ltest)[[1]]
  }
  
  return(results)
}
```


## Selección de clases de funciones a usar

Los modelos que vamos a intentar ajustar son los proporcionados por la función `glm` (Generalized Linear Models) de `R`. Para cada familia, siempre que admitan, utilizaremos distintas funciones de enlace. Las funciones de enlace nos permiten establecer una relación entre la media de la respuesta y los predictores del modelo. Las familias que vamos a considerar para el ajuste son:

- **Binomial**, con link **logit**. Regresión logística.
- **Binomial**, con link **probit**. Modelo binomial, con función de enlace $\Phi^{-1}(\mu)$, donde $\Phi$ es la distribución acumulada de la distribución normal.
- **Binomial**, con link **cauchit**. Modelo binomial, cuya función de enlace es la análoga a la del modelo anterior sobre una distribución de Cauhy, en lugar de la normal.
- **Gaussiana**, con link **identity**. Regresión lineal.
- **Gaussiana**, con link **log**. Distribución normal con función de enlace logarítmica.
- **Poisson**. Distribución de Poisson. 
- **Quasi**. Este modelo no tiene una varianza determinada como en el resto de familias. Indicaremos la especificación de varianza `"constant"`
- **Quasibinomial.** Distribución binomial, con la única diferencia de que no fija el parámetro de dispersión (intenta describir varianza adicional en los datos que no puede ser explicada mediant una distribución binomial).
- **Quasipoisson.** Distribución de Poisson, con la única diferencia de que no fija el parámetro de dispersion.



```{r, echo=F,warning=F}
calculateEtest <- function(ml, test, ltest, s=0){
  #Cálculo de probabilidades
  if(s==0){
    ml.prob_test = predict(ml, test, type="response")
  }else{
    ml.prob_test = predict(ml,as.matrix(test),type = "response", s = s)
  }

  # Etest
  ml.pred_test = rep(0, length(ml.prob_test)) # predicciones por defecto 0
  ml.pred_test[ml.prob_test >=0.5] = 1 # >= 0.5 clase 1
  

  ml.Etest = mean(ml.pred_test != ltest)
  
  return(list(ml.Etest, ml.pred_test))
}

calculateEin <- function(ml ,ltrain){
  ml.prob_train = predict(ml, type = "response") #no tenemos que introducirle el train porque recuerda
  # Ein
  ml.pred_train = rep(0, length(ml.prob_train)) #predicciones por defecto 0
  ml.pred_train[ml.prob_train >= 0.5] = 1
    
  ml.Ein = mean(ml.pred_train != ltrain)

  return(list(ml.Ein, ml.pred_train))
}

testFamilies <- function(models, test, ltrain, ltest, modelNames = NULL){

  results <- matrix(nrow=length(models), ncol = 2)
  colnames(results) <- c("Ein","Eout")
  if(!is.null(modelNames)){
    rownames(results) <- modelNames
  }
  for(i in seq_along(models)){
    results[i,1] <-calculateEin(models[[i]],ltrain)[[1]]
    results[i,2] <- 
      calculateEtest(models[[i]],test,ltest)[[1]]
  }
  
  return(results)
}
```


```{r, echo=F,warning=F}

# Validación (una sola vez)
validateFamilies <- function(data,label){
  #Muestra
  train <- sample(nrow(data),0.7*nrow(data))
  
  #Datos
  data.train <- data[train,]
  data.test <-  data[-train,]
  
  #Etiquetas
  label.train <- label[train]
  label.test <- label[-train]
  
  #Modelos
  #binomial
  ml.binomial1 <- glm(chd ~ ., family = binomial(logit), data = data, subset=train)
  ml.binomial2 <- glm(chd ~ ., family = binomial(probit), data = data, subset=train)
  ml.binomial3 <- glm(chd ~ ., family = binomial(cauchit), data = data, subset=train)
  #gaussiano
  ml.gaussian1 <- glm(chd ~ ., family = gaussian(identity), data = data, subset=train)
  ml.gaussian2 <- glm(chd ~ ., family = gaussian(log), data = data, subset=train, start=rep(0, ncol(data)+1))
  #poisson
  ml.poisson1 <- glm(chd ~ ., family = poisson(log), data = data, subset=train)
  
  #quasi
  ml.quasi1 <- glm(chd ~ ., family = quasi(link = "identity", variance = "constant"), data = data, subset=train)

  #quasibinomial
  ml.quasibinomial1 <- glm(chd ~ ., family = quasibinomial(link = "logit"), data = data, subset=train)
  #quasipoisson
  ml.quasipoisson1 <- glm(chd ~ ., family = quasipoisson(link = "log"), data = data, subset=train)  

  models <- list(ml.binomial1, ml.binomial2, ml.binomial3, ml.gaussian1, ml.gaussian2, ml.poisson1, ml.quasi1, ml.quasibinomial1, ml.quasipoisson1)
  modelNames <- c("Binomial - Logit", "Binomial - Probit", "Binomial - Cauchit", "Gaussian - Identity", "Gaussian - Log", "Poisson", "Quasi", "Quasibinomial","Quasipoisson")
  
  testFamilies(models, data.test, label.train, label.test, modelNames)
  
}

# Función para realizar multiples validaciones
repValidation <- function(rep,data,label){
  l <- replicate(n = rep, expr = validateFamilies(data,label))
  #l es una matriz 3D de rep x num_modelos x 2 (Ein,Eout)
  #l[,,i] -> experimento i-ésimo
  #[,i,] -> Ein / Eout de cada modelo en los distintos experimentos (i=1 Ein, i=2 Eout)
  #[i,,] -> Ein y Eout para el modelo i-ésimo en cada experimento
  apply(FUN = mean, X = l, MARGIN = c(1,2))
}

```

Una vez definidos los modelos y las funciones a usar, procedemos al ajuste de los distintos modelos y al análisis de sus errores:

```{r, echo=F, warning=F}
# Comprobamos qué método proporciona un menor error de validación con múltiples validaciones
repValidation(rep = 100, sahd.data, sahd.label)

# Confirmamos que el modelo que mejor generaliza es el la gaussiana2
ml.sahd <- glm(chd ~ ., family = poisson(log), data = sahd.data, subset=train, start=rep(0, ncol(sahd.data)+1))


```

Obtenemos que el modelo que mejores resultados proporciona es el de Poisson. Hay que destacar que los resultados de Poisson coinciden con los de quasipoisson, pero elegimos el de Poisson por ser más conocido.

## Regularización

A continuación nos planteamos la necesidad de regularización, sobre el mejor modelo que hemos obtenido. Para ello utilizamos la regularización lasso (least absolute shrinkage and selection operator). Lasso es un método que lleva a cabo la regularización a la misma vez que realiza selección de características. 

El objetivo se basa en reducir el error de predicción, para ello, se ocupa de reducir la función:

\[
  R(\beta) = \sum_{i=1}^{n}(y_i - x_i\omega)^2 + \lambda \sum_{i=1}^{p}|\omega_i|
\]

donde $n$ es el número de muestras y $p$ el número de atributos y $w$ el vector de pesos solución. Así, obtiene diferentes valores de $\lambda$. Entre estos valores devueltos, podemos considerar dos de ellos:

- *lambda.min*, que nos devuelve el valor del $\lambda$ para el que se minimiza el error obtenido.
- *lambda.1se*. Aunque el $\lambda$ anterior sea menor, presenta una mayor dependencia de las particiones seleccionadas en la validación cruzada. La regla `1se` (one standard error), elige un valor de $\lambda$ para lo suficiente cercano a `lambda.min` para el cual el modelo obtenido sea lo suficiente simple, reduciendo así la dependencia del error respecto a las validaciones.

Podemos contemplar cualquiera de estos valores de $\lambda$ para regularizar nuestro modelo. 

Para contestar a la pregunta de si era necesario aplicar regularización a nuestra base de datos, realizamos 100 experimentos en los que, para diferentes subconjuntos de datos de nuestra muestra calculamos el error al regularizar con ambos valores de $\lambda$ y al no regularizar. Debemos quedarnos con el modelo que menos error presente.

```{r, echo=F,warning=F}
  #library(glmnet)
  #El método para llamar a GLM con lasso (elasticnet regularization) es glmnet

  #En la documentación aqui parece que haya más families.

  #Mediante validación cruzada sacamos el mejor lambda

  testRegularization <- function(data, label, iter = 100){
      error1 <- 0
      error2 <- 0
      error3 <- 0
      
      for(i in 1:iter){
          train <- sample(nrow(data),0.7*nrow(data))
          data.train <- data[train,]
          data.test <- data[-train,]
          #Etiquetas
          ldata.train <- label[train]
          ldata.test <- label[-train]
          
          #Ponemos el link en las etiquetas pues a glmnet no se le puede pasar como argumento
          ml_lasso <- cv.glmnet(as.matrix(data.train), ldata.train, family="poisson")
          ml = ml.gaussian2 <- glm(chd ~ ., family = gaussian(log), data = data, subset=train, start=rep(0, ncol(data)+1))
    
          error1 <- error1 + calculateEtest(ml_lasso,data.test,ldata.test,ml_lasso$lambda.min)[[1]]
          error2 <- error2 +calculateEtest(ml_lasso,data.test,ldata.test,ml_lasso$lambda.1se)[[1]]
          error3 <- error3 +calculateEtest(ml,data.test,ldata.test)[[1]]
      }
    
      #print(error1/100)
      #print(error2/100)
      #print(error3/100)
      return(c(error1/iter,error2/iter,error3/iter))
  }

  l <- testRegularization(sahd.data, sahd.label, 100)
  
  cat("Etest con lambda min: ",l[1],"\n")
  cat("Etest con lambda 1se: ",l[2],"\n")
  cat("Etest con el modelo original: ",l[3],"\n")

```

Como podemos observar, el error medio obtenido es menor con el modelo sin regularizar, obteniendo así una respuesta negativa a la pregunta. Por tanto, seguiremos con el modelo sin regularización. <- JUANLU -> !!! LA TIA COMENTÓ AQUI ALGO DE LAS VARIANZAS CHICAS?? NO LO SÉ :S

A modo de ampliación, comentar que el método de regularización lasso, cuando devuelve los coeficientes nulos significa que está despreciando estos atributos para la predicción. Si imprimimos los coeficientes correspondientes al valor de *lambda.1se* observamos que los atriburos que no selecciona para la predicción son: sbp, adiposity, typea, obesity y alcohol.

```{r, echo=F,warning=F}
  ml_lasso <- cv.glmnet(as.matrix(sahd.train), lsahd.train, family="poisson")
  coeffs.1se <- coef(ml_lasso, s = ml_lasso$lambda.1se)
  print(coeffs.1se)
```

A continuación, en la selección del número de atributos a utilizar, veremos que dichos atributos son, en efecto, algunos de los que participan en menos combinaciones "óptimas", por lo tanto, serán algunos de los menos relevantes.

## Optimización del número de atributos para el modelo seleccionado

Para optimizar el número de atributos para el modelo seleccionado, vamos a hacer uso de la función llamada *regsubsets*, esta función junto con las opciones de *method = "exhaustive* y *nbest = 1* realizará una búsqueda exhaustiva del mejor atributo (el que produce menor error cuadrático), la mejor pareja de atributos, el mejor trío, etcétera. 

El método nos proporciona el siguiente esquema en el que podemos apreciar las combinaciones de atributos elegidos.

```{r, echo=F,warning=F}

  #method = "exhaustive" para que no sea greedy.
  testing <- regsubsets(chd ~ ., data = sahd.data, nbest = 1, method = "exhaustive")

  #Obtenemos una tablita con los que es mejor coger.
  stesting <- summary(testing)
  print(stesting$outmat)
```

En este punto nos planteamos cuántos atributos utilizar para nuestro modelo. Claramente, cuantos más atributos utilicemos menor será el error producido en la muestra. Esto lo podemos corroborar dibujando la gráfica del error por mínimos cuadrados en función del número de atributos elegidos.

```{r, echo=F,warning=F}

  #Dibujar -> testing$ress
  plot(testing$ress, col = "red", pch = 19, type = "b")
```

Sin embargo, debemos de plantearnos qué número de atributos sería el óptimo si penalizáramos también el número de atributos utilizados. Es decir, cuándo una función que combine el error producido junto con el número de atributos utilizado se minimiza. Para ello utilizamos la función *BIC*, cuya gráfica en función del número de atributos podemos observar a continuación: 

```{r, echo=F,warning=F}

  plot(stesting$bic, col = "blue", pch = 19, type = "b")
```
  
  El criterio BIC (Bayesian Information Criterion) se basa en seleccionar el modelo con menor función BIC asociada. La función BIC es una función que depende logarítmicamente del tamaño de la muestra $n$, el número de atributos $k$ y el estimador máximo verosímil, $\hat{L}$. Concretamente, $BIC = \ln(n)k-2\ln(\hat{L})$ Dicha función alcanza un mínimo con 5 atributos, por tanto, este será el número de atributos que utilizaremos para nuestro modelo.
  
```{r, echo=F,warning=F}

  sahd.data <- sahd.data[,c(2,3,5,6,9)]
```

## Transformación de atributos

A continuación, nos planteamos la búsqueda de una transformación polinómica de los atributos para la cual nuestro modelo tenga una mayor capacidad de aprender y predecir nuestro conjunto de datos. Para ello utilizamos un algoritmo de búsqueda greedy. Para cada atributo, vamos eligiendo distintos exponentes y nos quedamos con el exponente que proporcione menor error de validación. Cuando llegamos al siguiente atributo, aplicamos el mismo procedimiento, manteniendo para los atributos anteriores el mejor exponente encontrado. Además, como cuando dos modelos proporcionan resultados similares siempre es mejor quedarse con el más simple, fijaremos una tolerancia para la cual, si no hay mejoras significativas en la nueva transformación, nos quedemos con la transformación mejor obtenida previamente, que tendrá un exponente menor y por tanto será más simple el ajuste.

```{r, echo=F,warning=F}
testPolyTransform <- function(data,label){
  #Muestra
  train <- sample(nrow(data),0.7*nrow(data))
  
  #Datos
  data.train <- data[train,]
  data.test <-  data[-train,]
  
  #Etiquetas
  label.train <- label[train]
  label.test <- label[-train]
  
  #Usamos el modelo ganador
  ml <- glm(chd ~., family = gaussian(log), data = data, subset =train,start=rep(0, ncol(data)+1))
  
  models <- list(ml)
  
  testFamilies(models, data.test, label.train, label.test)
  
}

testPolyTransformRep <- function(rep,data,label){
   l <- replicate(n = rep, expr = testPolyTransform(data,label))
  #l es una matriz 3D de rep x num_modelos x 2 (Ein,Eout)
  #l[,,i] -> experimento i-ésimo
  #[,i,] -> Ein / Eout de cada modelo en los distintos experimentos (i=1 Ein, i=2 Eout)
  #[i,,] -> Ein y Eout para el modelo i-ésimo en cada experimento
  apply(FUN = mean, X = l, MARGIN = c(1,2))
}

# Devuelve un vector de coeficientes para cada atributo
# tol: Nivel de tolerancia: si dos Eout se diferencian en menos de Eout, escogemos el coeficiente más simple
polynomialTransformGreedy <- function(data,label,max_coeff, tol = 0){
  transform <- data
  coeffs <- c()

  for(i in 1:ncol(transform)){
    bestEout <- 1
    bestInd <- 0
    for(j in 1:max_coeff){
      transform[,i] <- I(data[,i]^j)
      v <- testPolyTransformRep(100,transform,label)
      # Comparamos con Etest
      if(v[2] + tol < bestEout){
        bestEout <- v[2]
        bestInd <- j
      }
      cat("Attr = ",i,", Exp = ",j,", ","Ein = ", v[1], "Eout = ",v[2],"\n")
    }
    #Nos quedamos con el mejor coeficiente obtenido para el atributo
    transform[,i] <- I(data[,i]^bestInd)
    coeffs <- c(coeffs,bestInd)
  }
  # Por ser greedy con el mecanismo escogido el mejor Eout va a ser el de la última iteración
  list(coeffs,bestEout)
}
```

Aplicamos el algoritmo. Los resultados obtenidos son:

```{r, echo=F,warning=F}
l <- polynomialTransformGreedy(sahd.data,sahd.label,6, tol = 0.01)
cat("Vector de exponentes: ", l[[1]])
cat("Eout estimado: ",l[[2]])

```

Vemos que, para exponentes de hasta tamaño 6 no se aprecian mejoras significativas con respecto a los coeficientes lineales iniciales.

## Conclusiones.

Por tanto, el modelo óptimo escogido es un modelo lineal que utiliza los atributos tobacco, ldl, present_famhist, typea y age. A este conjunto de datos le aplicamos una regresión de Poisson obteniendo un error estimado del 26.46763\%. Es decir, tras todos los modelos probados el error no ha conseguido disminuir del 25 %, lo que nos indica que los datos no son separables en gran medida. Esto se puede ilustrar en la siguiente gráfica, en la que se muestran los atributos finales escogidos comparados dos a dos, junto con la clase que determina el dato en cuestión. Vemos que en general, es difícil apreciar patrones de separación (aunque esto no nos asegura nada, puesto que la dimensión del número de atributos es mayor, y comparándolos 2 a 2 no se puede afirmar nada sobre la separabilidad real del conjunto).

```{r, echo=F,warning=F}
pairs( ~ tobacco + ldl + present_famhist + typea + age, data=sahd.data, col = chd+3)

```

En la gráfica anterior podemos observar además que hay atributos que separan las clases con mayor facilidad, por ejemplo, `age` y `ldl`. Podemos probar a clasificar los datos usando solo estos atributos, obteniendo los siguientes resultados:

```{r, echo=F,warning=F}

ml <- glm(chd ~ typea+age , family = poisson(log), data = sahd.data, subset=train)


ml.probtrain <- predict(ml.sahd,type="response")
ml.predtrain <- rep(0,length(ml.probtrain))
ml.predtrain[ml.probtrain >= 0.5]=1
ml.Ein = mean(ml.predtrain != lsahd.train)
  
ml.probtest <- predict(ml,sahd.test,type="response")
ml.predtest <- rep(0,length(ml.probtest))
ml.predtest[ml.probtest >= 0.5]=1
ml.Etest = mean(ml.predtest != lsahd.test)

cat("Ein = ",ml.Ein,"\n")
cat("Etest = ",ml.Etest,"\n")

coefs_recta_explicita <- function(coefs_recta_impl){
  return(c(-coefs_recta_impl[2]/coefs_recta_impl[3],-coefs_recta_impl[1]/coefs_recta_impl[3]))
}

#plot(typea,age,col = chd + 3)
#r <- coefs_recta_explicita(ml$coefficients)
#abline(r[2],r[1],col="red")

```

Es decir, de entre el par de atributos que mejor aparenta separar los datos, el error es bastante elevado, y al optimizar el número de atributos, aunque el error sigue siendo alto, conseguimos reducirlo bastante. Esto nos permite observar que el modelo ajustado, dentro de la poca separabilidad de los datos, es de calidad (?)

También hemos comprobado que, en general, el conjunto de datos es poco sensible a la regularización y a las transformaciones. Sobre esto último, al no haber diferencias relevantes con respecto a ninguna transformación polinómica, se mantiene la linealidad en los datos, puesto que entre modelos similares, siempre es mejor quedarnos con el de mayor simplicidad.

# Regresión. 

Para el problema de regresión hemos elegido la base de datos de *Los Ángeles Ozone*, la cual se centra en medir el nivel de concentración de ozono en la atmósfera. Para ello, se realizaban 8 mediciones hechas diariamente en Los Ángeles durante el año 1976. Aunque la idea era obtener el nivel de ozono para todos los días del año, algunos datos se han perdido así que no contiene todos los días del año (en concreto contiene 330 días). La base de datos consta de 10 atributos que son los siguientes:

- **ozone**: Es la variable de respuesta, mide la elevación máxima del ozono. 
- **vh**: Vandenberg 500 mb Height
- **wind**: Velocidad del viento, medida en mph.
- **humidity:** Tanto por ciento de humedad.
- **temp:** Temperatura
- **ibh:** !!!
- **dpg:** Gradiente de presión de Daggot.
- **ibt:** 
- **vis:** La visibilidad medida en millas.
- **day:** Día del año en el que se realizó la medición.

```{r echo = FALSE, warning=FALSE}
    #PREPARACIÓN DE LOS DATOS
    ozone.df <- read.table("./data/ozone", sep=",",head=T)
    summary(ozone.df)
    
   # dim(ozone.df)
    
    attach(ozone.df)

```

A continuación, se muestra una comparativa de todos los atributos 2 a 2 mediante gráficas, la cual nos puede ayudar más adelante a estimar el comportamiento no lineal de algunos atributos:

```{r, echo=F,warning=F}

    pairs( ~ozone + vh + wind + humidity + temp + ibh +dpg + ibt + vis + doy, data= ozone.df, col = "red")
```

Realmente, las gráficas que más nos interesan son las de la primera fila, puesto que muestran `ozone`, el atributo sobre el que queremos hacer regresión, en función del resto de atributos. Aunque también, el resto de gráficas nos puede permitir intuir dependencias entre atributos, lo que nos puede conducir a la eliminación de algunos cuya información ya esté presente en otro atributo.

## Preprocesamiento de datos

Como en el problema de clasificación, procedemos a procesar los datos para reducir asimetrías, escalarlos y centrarlos. De nuevo, como trabajamos con un número pequeño de atributos, no aplicaremos PCA para la reducción de atributos.

```{r, echo=F, warning=F}

#library(caret)

#No aplicamos PCA pues pierde variabilidad.
ObjetoTrans2 = preProcess(ozone.df[,names(ozone.df)!="ozone"],method = c("BoxCox","center","scale"))



ozoneTrans <- predict(ObjetoTrans2,ozone.df)
#dim(ozoneTrans)

```

A continuación, vemos de nuevo la distribución de atributos 2 a 2 una vez preprocesados los datos. Comprobamos, como ya se comentó en la clasificación, que, aunque hayan cambiado las escalas y las posiciones de los datos en las gráficas (basta ver los valores que muestran los ejes), las formas en las que se distribuyen los datos en las gráficas siguen siendo las mismas:

```{r,echo=F,warning=F}

attach(ozoneTrans)
pairs( ~ozone + vh + wind + humidity + temp + ibh +dpg + ibt + vis + doy, data= ozoneTrans, col = "blue")
```

## Conjuntos de validación, training y test usados.

A continuación pasaremos a explorar los distintos modelos sobre los que resolver el problema de regresión para nuestro conjunto de datos. Al igual que en regresión, el procedimiento de validación que usaremos consistirá en tomar múltiples veces distintos conjuntos de entrenamiento sobre nuestro conjunto de datos (una vez transformados), con los que aprenderemos el modelo. Usaremos el resto del conjunto como test para evaluar cómo de bien predice el modelo aprendido con nuevos datos. Las proporciones utilizadas serán de nuevo del 70 % de los datos para train, y el 30 % para test.

```{r, echo=F, warning=F}
  #Paso 5: Preparación de conjunto de train/test, y de las etiquetas train/test
  ozone.data <- ozoneTrans[,-1]
  ozone.label <- ozoneTrans[,1]
  #sahd.label[sahd.label==0] <- -1 
  
  train <- sample(nrow(ozone.df),0.7*nrow(ozone.df))
  ozone.train <- ozone.data[train,]
  ozone.test <- ozone.data[-train,]
  
  #Etiquetas
  lozone.train <- ozone.label[train]
  lozone.test <- ozone.label[-train]
  
```


## Selección de clases de funciones a usar

Procedemos ahora a la selección de modelos de regresión. El modelo seleccionado para este caso es el de regresión lineal clásico, que podemos utilizar en `R` mediante la función `lm`.

```{r, echo=F,warning=F}
calculateEtestRegression <- function(mr, test, ltest, s = 0){
    if(s==0){
      mr.pred_test = predict(mr, test, type="response")
    }else{
      mr.pred_test = predict(mr,as.matrix(test),type = "response", s = s)
    }
    #mr.pred_test = predict(mr, test, type="response")
    mr.Etest <- mean((mr.pred_test-ltest)^2)
    
    return(list(mr.Etest,mr.pred_test))
}

calculateEinRegression <- function(mr ,ltrain){
    mr.pred_train = predict(mr,type = "response")
    mr.Ein <- mean((mr.pred_train-ltrain)^2)

    return(list(mr.Ein, mr.pred_train))
}

testFamiliesRegression <- function(models, test, ltrain, ltest){

  results <- matrix(nrow=length(models), ncol = 2)
  colnames(results) <- c("Ein","Eout")
  for(i in seq_along(models)){
    results[i,1] <-calculateEinRegression(models[[i]],ltrain)[[1]]
    results[i,2] <- 
      calculateEtestRegression(models[[i]],test,ltest)[[1]]
  }
  
  return(results)
}
```

```{r, echo=F,warning=F}

# Validación (una sola vez)
validateFamiliesRegression <- function(data,label){
  #Muestra
  train <- sample(nrow(data),0.7*nrow(data))
  
  #Datos
  data.train <- data[train,]
  data.test <-  data[-train,]
  
  #Etiquetas
  label.train <- label[train]
  label.test <- label[-train]
  
  #Modelos
  mr1 = lm(ozone ~ ., data, train)


  models <- list(mr1)
  
  testFamiliesRegression(models, data.test, label.train, label.test)
  
}

# Función para realizar multiples validaciones
repValidationRegression <- function(rep,data,label){
  l <- replicate(n = rep, expr = validateFamiliesRegression(data,label))
  #l es una matriz 3D de rep x num_modelos x 2 (Ein,Eout)
  #l[,,i] -> experimento i-ésimo
  #[,i,] -> Ein / Eout de cada modelo en los distintos experimentos (i=1 Ein, i=2 Eout)
  #[i,,] -> Ein y Eout para el modelo i-ésimo en cada experimento
  apply(FUN = mean, X = l, MARGIN = c(1,2))
}

```

Una vez definido el modelo, procedemos a su ajuste y al análisis de los errores obtenidos:

```{r, echo=F,warning=F}
  repValidationRegression(100,ozone.data,ozone.label)
```


## Regularización.

Al igual que en el problema de clasificación, obtendremos dos valores de lambda y compararemos los errores producidos con cada uno de estos valores y con el modelo anterior, sin aplicar regularización.

```{r, echo=F,warning=F}

testRegularizationRegression <- function(data, label, iter = 100){
      error1 <- 0
      error2 <- 0
      error3 <- 0
      
      for(i in 1:iter){
          train <- sample(nrow(data),0.7*nrow(data))
          data.train <- data[train,]
          data.test <- data[-train,]
          #Etiquetas
          ldata.train <- label[train]
          ldata.test <- label[-train]
          
          #Ponemos el link en las etiquetas pues a glmnet no se le puede pasar como argumento
          #grid=10^seq(10,-2,length=100)
          ml_lasso <- cv.glmnet(as.matrix(data.train), ldata.train)
          ml = lm(ozone ~ ., data, train)
    
          error1 <- error1 + calculateEtestRegression(ml_lasso,data.test,ldata.test,ml_lasso$lambda.min)[[1]]
          error2 <- error2 +calculateEtestRegression(ml_lasso,data.test,ldata.test,ml_lasso$lambda.1se)[[1]]
          error3 <- error3 +calculateEtestRegression(ml,data.test,ldata.test)[[1]]
      }
    
      return(c(error1/iter,error2/iter,error3/iter))
  }
```

Los errores producidos han sido:

```{r, echo=F,warning=F}
  #library(glmnet)


  l <- testRegularizationRegression(ozone.data, ozone.label, 100)

  cat("Etest con lambda min: ",l[1],"\n")
  cat("Etest con lambda 1se: ",l[2],"\n")
  cat("Etest con el modelo original: ",l[3],"\n")
```

A diferencia de en el problema de clasificación, hemos obtenido que el menor error se consigue con *lambda.min*, aunque la diferencia con el modelo sin regularización es insignificante, y por tanto la regularización no es necesaria.


## Optimización del número de atributos para el modelo seleccionado

Al igual que en la clasificación, vamos a elegir el número de atributos que consideramos para nuestro modelo. Análogamente, realizaremos una búsqueda exhaustiva de las mejores combinaciones de atributos. Obtenemos que el esquema resultante es el siguiente:

```{r, echo=F,warning=F}
  #method = "exhaustive" para que no sea greedy.
  testing <- regsubsets(ozone ~ ., data = ozone.data, nbest = 1, method = "exhaustive")

  #Obtenemos una tablita con los que es mejor coger.
  stesting <- summary(testing)
  print(stesting$outmat)
```

Dibujamos también la gráfica descendente de errores *ress*:

```{r, echo=F,warning=F}
  #Dibujar -> testing$ress
  plot(testing$ress, col = "red", pch = 19, type = "b")
```

De forma análoga al ejercicio anterior, dibujamos la gráfica de *BIC* para determinar qué número de atributos optimiza el error junto con el número de atributos obtenido.

```{r, echo=F,warning=F}

  plot(stesting$bic, col = "blue", pch=19, type = "b")
  
  ozone.data_regu <- ozone.data[c(3,4,7,9)]

```

En este caso, aunque no es tan evidente como en el ejercicio de clasificación, vemos que el mínimo de la función *BIC* se alcanza en cuatro atributos, luego nos quedamos con la mejor combinación de cuatro atributos. Esta es, la que observamos en el esquema del *regsubsets*:  humidity, temp, ibt, doy.

## Transformación de atributos

Como hicimos en clasificación, procedemos ahora a buscar transformaciones polinómicas que permitan un mejor ajuste de los datos, recurriendo para ello al mismo algoritmo greedy utilizado en clasificación.

```{r, echo=F,warning=F}
testPolyTransformRegression <- function(data,label){
  #Muestra
  train <- sample(nrow(data),0.7*nrow(data))
  
  #Datos
  data.train <- data[train,]
  data.test <-  data[-train,]
  
  #Etiquetas
  label.train <- label[train]
  label.test <- label[-train]
  
  #Usamos el modelo ganador
  mr <- lm(ozone ~ ., data, train)
  
  models <- list(mr)
  
  testFamiliesRegression(models, data.test, label.train, label.test)
  
}

testPolyTransformRepReg <- function(rep,data,label){
   l <- replicate(n = rep, expr = testPolyTransformRegression(data,label))
  #l es una matriz 3D de rep x num_modelos x 2 (Ein,Eout)
  #l[,,i] -> experimento i-ésimo
  #[,i,] -> Ein / Eout de cada modelo en los distintos experimentos (i=1 Ein, i=2 Eout)
  #[i,,] -> Ein y Eout para el modelo i-ésimo en cada experimento
  apply(FUN = mean, X = l, MARGIN = c(1,2))
}

# Devuelve un vector de coeficientes para cada atributo
# tol: Nivel de tolerancia: si dos Eout se diferencian en menos de Eout, escogemos el coeficiente más simple
polynomialTransformGreedyRegression <- function(data,label,max_coeff, tol = 0){
  transform <- data
  coeffs <- c()

  for(i in 1:ncol(transform)){
    bestEout <- Inf
    bestInd <- 0
    for(j in 1:max_coeff){
      transform[,i] <- I(data[,i]^j)
      v <- testPolyTransformRepReg(100,transform,label)
      # Comparamos con Etest
      if(v[2] + tol < bestEout){
        bestEout <- v[2]
        bestInd <- j
      }
      cat("Attr = ",i,", Exp = ",j,"Ein = ",v[1], ", Eout = ",v[2],"\n")
    }
    #Nos quedamos con el mejor coeficiente obtenido para el atributo
    transform[,i] <- I(data[,i]^bestInd)
    coeffs <- c(coeffs,bestInd)
  }
  # Por ser greedy con el mecanismo escogido el mejor Eout va a ser el de la última iteración
  list(coeffs,bestEout)
}
```

```{r, echo=F,warning=F}

l <- polynomialTransformGreedyRegression(ozone.data_regu,ozone.label,4, tol = 0.01)

cat("Vector de exponentes: ", l[[1]],"\n")
cat("Eout estimado: ",l[[2]],"\n")

```

En este caso vemos que sí hay transformaciones polinómicas que mejoran el ajuste, luego esta transformacion polinómica será la elegida para el modelo final.

A modo de ampliación, aunque ya habíamos reducido nuestro conjunto de datos a cuatro atributos, vamos a probar las trasnformaciones no lineales sobre todos los atributos.

```{r, echo=F,warning=F}

l <- polynomialTransformGreedyRegression(ozone.data,ozone.label,4, tol = 0.01)

cat("Vector de exponentes: ", l[[1]],"\n")
cat("Eout estimado: ",l[[2]],"\n")

```

Como podemos observar, en este caso hemos obtenido un error menor al obtenido anteriormente, aunque esto se ha hecho a expensas de utilizar más atributos, lo que conlleva una mayor carga de cómputo. Aunque en este ejercicio no es un problema dado la reducida dimensión del conjunto de datos a utilizar, es importante tener un balance entre el error producido y el número de atributos considerado.

## Conclusiones

Por los resultados que hemos ido obteniendo anteriormente, el modelo final escogido sería aplicar el método *lm* a la base de dats con los cuatro atributos: humidity, temp, ibt, doy. El error estimado sería del 19.87646\%.

En cuanto a las transformaciones no lineales obtenidas sobre todos los atributos, podemos ver que se corresponden con la relación entre ozone y el resto de atributos que podemos observar en la tabla de la sección de Preprocesamiento de datos. Observamos que los atributos vh, dpg y doy tienen un comportamiento cuadrático. El comportamiento de doy se confirma cuando probamos transformaciones no lineales sobre los cuatro atributos escogidos para el modelo final. 
